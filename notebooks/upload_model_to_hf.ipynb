{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cf3fc4-f041-417f-82e8-dfa58e51b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "token = os.getenv(\"HF_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b338f5f4-6fd2-43aa-9576-1ea5669da266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths variables, to change accordingly to your needs\n",
    "pt_file_names = [\n",
    "    \"XLM_base_age_4g.pt\",\n",
    "    \"XLM_large_age_4g.pt\",\n",
    "    \"XLM_base_age_5g.pt\",\n",
    "    \"XLM_large_age_5g.pt\"\n",
    "    \"XLM_large_age_5g_extra_features.pt\",\n",
    "    #\"XLM_base_gender.pt\",\n",
    "    \"XLM_large_gender.pt\",\n",
    "    \"XLM_large_gender_extra_features.pt\",\n",
    "\n",
    "]\n",
    "hf_model_names = [\n",
    "    \"twitter-xlm-base-user-age-4g-it\",\n",
    "    \"twitter-xlm-large-user-age-4g-it\"\n",
    "    \"twitter-xlm-base-user-age-5g-it\",\n",
    "    \"twitter-xlm-large-user-age-5g-it\",\n",
    "    \"twitter-xlm-large-user-age-5g-it-extra\",\n",
    "    #\"twitter-xlm-base-user-gender-it\",\n",
    "    \"twitter-xlm-large-user-gender-it\",\n",
    "    \"twitter-xlm-large-user-gender-it-extra\",\n",
    "]\n",
    "\n",
    "pt_file_names = [\n",
    "    \"XLM_base_age_4g.pt\",\n",
    "]\n",
    "hf_model_names = [\n",
    "    \"twitter-xlm-base-user-age-4g-it\",\n",
    "]\n",
    "\n",
    "tokenizer_name_base = 'cardiffnlp/twitter-xlm-roberta-base'\n",
    "tokenizer_name_large = 'cardiffnlp/twitter-xlm-roberta-large-2022'\n",
    "cache_dir = '/g100_work/IscrC_mental/cache/huggingface/hub'\n",
    "pts_dir = '/g100_work/IscrC_mental/data/user_classification/XLM_models'\n",
    "hf_gits_dir = '/g100/home/userexternal/llupo000/hf_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c21d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Lupo/twitter-xlm-gender-prediction-italian\n",
      "On branch main\n",
      "Your branch is ahead of 'origin/main' by 1 commit.\n",
      "  (use \"git push\" to publish your local commits)\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Enumerating objects: 8, done.\n",
      "Counting objects: 100% (8/8), done.\n",
      "Delta compression using up to 24 threads\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects:  42% (3/7), 701.83 MiB | 19.85 MiB/s\r"
     ]
    }
   ],
   "source": [
    "# upload models to huggingface\n",
    "for pt_file_name, hf_model_name in zip(pt_file_names, hf_model_names):\n",
    "\n",
    "    # load tokenizer and model\n",
    "    if 'base' in hf_model_name:\n",
    "        tokenizer_path = tokenizer_name_base\n",
    "    elif 'large' in hf_model_name:\n",
    "        tokenizer_path = tokenizer_name_large\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, cache_dir=cache_dir)\n",
    "    print(f\"Loaded tokenizer {tokenizer_path}\")\n",
    "    model = torch.load(os.path.join(pts_dir, pt_file_name), map_location=torch.device('cpu'))\n",
    "    print(f\"Loaded model {pt_file_name}\")\n",
    "\n",
    "    # save tokenizer and model\n",
    "    save_dir = os.path.join(hf_gits_dir, hf_model_name)\n",
    "    tokenizer.save_pretrained(save_dir)\n",
    "    print(f\"Saved tokenizer in {save_dir}\")\n",
    "    model.module.save_pretrained(save_dir)\n",
    "    print(f\"Saved model in {save_dir}\")\n",
    "    \n",
    "    # Define shell commands\n",
    "    commands = [\n",
    "            f\"cd {save_dir}\",\n",
    "            \"echo '*.json filter=lfs diff=lfs merge=lfs -text' >> .gitattributes\",\n",
    "            \"git lfs install\",\n",
    "            \"git add .\",\n",
    "            \"git commit -am 'first commit'\",\n",
    "            \"git push origin main\"\n",
    "        ]\n",
    "    command = \" && \".join(commands)\n",
    "    # Execute the command\n",
    "    os.system(command)\n",
    "        \n",
    "    print(f\"Uploaded {hf_model_name} to huggingface\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
