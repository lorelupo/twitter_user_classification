{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14cf3fc4-f041-417f-82e8-dfa58e51b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import pipeline, set_seed\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16e1e82-d14c-4e3c-b7ae-3874d58cc94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dbf686c-6b1b-4fbe-9428-c4a4cbd520f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize(X_text, tokenizer, max_length=512, batch_size=64):\n",
    "\n",
    "    # Dictionary to hold tokenized batches\n",
    "    encodings = {}\n",
    "\n",
    "    # Calculate the number of batches needed\n",
    "    num_batches = len(X_text) // batch_size + int(len(X_text) % batch_size > 0)\n",
    "\n",
    "    # Iterate over the data in batches\n",
    "    for i in range(num_batches):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = min(len(X_text), (i + 1) * batch_size)\n",
    "\n",
    "        # Tokenize the current batch of texts\n",
    "        batch_encodings = tokenizer.batch_encode_plus(\n",
    "            list(X_text[batch_start:batch_end]),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "        # Merge the batch tokenizations into the main dictionary\n",
    "        for key, val in batch_encodings.items():\n",
    "            if key not in encodings:\n",
    "                encodings[key] = []\n",
    "            encodings[key].extend(val)\n",
    "\n",
    "    return encodings\n",
    "\n",
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def compute_metrics(model, data_loader, device, average):\n",
    "    with torch.no_grad():\n",
    "        all_predictions = []\n",
    "        all_labels = []\n",
    "\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get the predicted class labels\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        \n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        #precision = precision_score(all_labels, all_predictions)\n",
    "        #recall = recall_score(all_labels, all_predictions)\n",
    "        if average == 'binary':\n",
    "            f1 = f1_score(all_labels, all_predictions)\n",
    "        else:\n",
    "            f1 = f1_score(all_labels, all_predictions, average = average)\n",
    "        metrics = {'accuracy': accuracy,  'f1': f1 }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "def test_eval(model, data_loader, device, compute_performance=False, average='binary'):\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # store predicted probs\n",
    "    class_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "\n",
    "            # Convert logits to probabilities\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            class_probs.extend(probabilities.cpu().numpy().tolist())\n",
    "            \n",
    "    # Compute the metrics\n",
    "    if compute_performance:\n",
    "        metrics = compute_metrics(model, data_loader, device, average=average)\n",
    "        return metrics, np.array(class_probs)\n",
    "    \n",
    "    return np.array(class_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7422cf2-5d8c-4df4-939f-8e146cf7e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set from german data\n",
    "path  = os.path.join(uc_dir, 'german_data/data_for_models_german_data.pkl')\n",
    "df_test = pd.read_pickle(path)\n",
    "\n",
    "df_test['male'] = df_test['is_male'].astype(int)\n",
    "df_test['text']  = 'bio: ' + df_test['masked_bio'] + '. ' + 'tweets: ' + df_test['long_text'] \n",
    "df_test['text'] = df_test['text'].str.replace('\\r|\\n', ' ', regex=True)\n",
    "\n",
    "X_test = df_test['text'].values\n",
    "y_test = df_test['male'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df4c10a0-85b2-4513-8c6b-65a042bac990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab667d1cd494f638d4e25142718a334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe143d8a44a24158bdcdf6c7170fc3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f07008b9e134554a0d6fe1264e515fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/167 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize features\n",
    "xlm_tokenizer = AutoTokenizer.from_pretrained(\"lorelupo/twitter-xlm-gender-prediction-italian\")\n",
    "xlm_test_encodings = batch_tokenize(X_test, xlm_tokenizer)\n",
    "# create dataset and its loader\n",
    "xlm_test_dataset = TweetDataset(xlm_test_encodings, y_test)\n",
    "xlm_loader = torch.utils.data.DataLoader(\n",
    "    xlm_test_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1006523a-b787-4f0a-8b3f-80ef47329b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "xlm_gender = AutoModelForSequenceClassification.from_pretrained(\"lorelupo/twitter-xlm-gender-prediction-italian\")\n",
    "xlm_gender = xlm_gender.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a576158a-3798-4169-96f9-77f077fb0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model over test set and compute metrics\n",
    "metrics, probs = test_eval(xlm_gender, xlm_loader, DEVICE, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8478f2e8-0f42-4719-b7f1-57d908e21bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8195876288659794, 'f1': 0.8833333333333333}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea861b95-7064-4bdc-87cd-1af2431b9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = [{'user_id':x,'prob_female':y[0],'prob_male':y[1]} for x,y in zip(df_test['user_id'],probs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7144df45-c2d6-4620-b7a7-0a70a2f4728b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>prob_female</th>\n",
       "      <th>prob_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3430018155</td>\n",
       "      <td>0.095967</td>\n",
       "      <td>0.904033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>269803152</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.993245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1372423700</td>\n",
       "      <td>0.299473</td>\n",
       "      <td>0.700527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1184400427988803584</td>\n",
       "      <td>0.135628</td>\n",
       "      <td>0.864372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2951843386</td>\n",
       "      <td>0.472516</td>\n",
       "      <td>0.527484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1178286769353175040</td>\n",
       "      <td>0.037096</td>\n",
       "      <td>0.962904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>407722041</td>\n",
       "      <td>0.224812</td>\n",
       "      <td>0.775188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>3140335966</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.998720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>899250898127507456</td>\n",
       "      <td>0.842391</td>\n",
       "      <td>0.157609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>743789411171721216</td>\n",
       "      <td>0.259775</td>\n",
       "      <td>0.740225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  prob_female  prob_male\n",
       "0             3430018155     0.095967   0.904033\n",
       "1              269803152     0.006755   0.993245\n",
       "2             1372423700     0.299473   0.700527\n",
       "3    1184400427988803584     0.135628   0.864372\n",
       "4             2951843386     0.472516   0.527484\n",
       "..                   ...          ...        ...\n",
       "383  1178286769353175040     0.037096   0.962904\n",
       "384            407722041     0.224812   0.775188\n",
       "385           3140335966     0.001280   0.998720\n",
       "386   899250898127507456     0.842391   0.157609\n",
       "387   743789411171721216     0.259775   0.740225\n",
       "\n",
       "[388 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame.from_records(records)\n",
    "df_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "mentalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
