{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478ab7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd70b1-ea88-4e1a-959c-083aca7fe0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/g100_work/IscrC_mental/data/user_classification/M3_results_de_bio_image.json') as f:\n",
    "    r = json.load(f)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3c3b52-2b80-425a-8353-4040bf279f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(606, 7)\n",
      "(420, 7)\n",
      "\n",
      "(388, 21)\n",
      "(384, 21)\n",
      "\n",
      "(384, 21)\n",
      "(384, 21)\n",
      "\n",
      "(384, 5)\n"
     ]
    }
   ],
   "source": [
    "test_set = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/german_data/data_for_models_german_data.pkl')\n",
    "german_all = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/de/all_models_test.pkl')\n",
    "xlm_de = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/de/xlm_test.pkl')\n",
    "\n",
    "m3_label_dict = {0:'0_18',1:'19_29',2:'30_39',3:'40_100'}\n",
    "\n",
    "def json_to_df(data_json):\n",
    "    rows = []\n",
    "    for user_id, data in data_json.items():\n",
    "        row = {}\n",
    "        row['user_id'] = user_id\n",
    "        row['m3_prob_female'] = data['gender'].get('female', 0)\n",
    "        row['m3_prob_male'] = data['gender'].get('male', 0)\n",
    "        age_classes = list(data['age'].values())\n",
    "        for idx, age_value in enumerate(age_classes):\n",
    "            row[f'm3_prob_{m3_label_dict[idx]}'] = age_value\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['user_id'] = df['user_id'].astype('float64')\n",
    "    return df\n",
    "\n",
    "with open('/g100_work/IscrC_mental/data/user_classification/M3_results_de_bio_image.json') as f:\n",
    "    r = json.load(f)\n",
    "m3_de = json_to_df(r)\n",
    "\n",
    "german_all.user_id = german_all.user_id.astype('float')\n",
    "xlm_de.user_id = xlm_de.user_id.astype('float')\n",
    "m3_de.user_id = m3_de.user_id.astype('float')\n",
    "\n",
    "print(xlm_de.shape)\n",
    "print(m3_de.shape)\n",
    "print()\n",
    "\n",
    "xlm_de = german_all.merge(xlm_de, on='user_id', how='inner')\n",
    "m3_de = german_all.merge(m3_de, on='user_id', how='inner')\n",
    "\n",
    "print(xlm_de.shape)\n",
    "print(m3_de.shape)\n",
    "print()\n",
    "\n",
    "xlm_de = xlm_de[xlm_de.user_id.isin(m3_de.user_id)]\n",
    "\n",
    "print(xlm_de.shape)\n",
    "print(m3_de.shape)\n",
    "print()\n",
    "\n",
    "test_set = test_set[test_set.user_id.isin(m3_de.user_id)]\n",
    "\n",
    "print(test_set.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a1e31c-92c0-4d03-b789-90c350c36824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_features(\n",
    "    df,\n",
    "    include_bio=True,\n",
    "    include_tweets=True,\n",
    "    label_name='is_male',\n",
    "    ):\n",
    "    # Read the gold labels\n",
    "    if label_name == 'is_male':\n",
    "        gold_labels = df[label_name].tolist()\n",
    "        gold_labels = ['male' if label == True else 'female' for label in gold_labels]\n",
    "    if label_name == 'age':\n",
    "        gold_labels = df[label_name].astype(int).tolist()\n",
    "    if label_name == 'age_interval':\n",
    "        # define age classes\n",
    "        age_intervals = [0, 20, 30, 40, 100]\n",
    "        age_labels = [0, 1, 2, 3]\n",
    "        # Discretize the 'age' column into four classes\n",
    "        gold_labels = pd.cut(df['age'], bins=age_intervals, labels=age_labels, right=False).astype('int').tolist()\n",
    "\n",
    "    return _, gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a31ef0-4174-42c7-b271-7e3fb9c848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_performace(p1, p2, gold_labels, class_means=[]):\n",
    "    \n",
    "    gold_labels = np.array(gold_labels)\n",
    "\n",
    "    # compute predictions\n",
    "    pred1 = p1.argmax(axis=1) \n",
    "    pred2 = p2.argmax(axis=1)\n",
    "    \n",
    "    print(Counter(pred1))\n",
    "    print(Counter(pred2))\n",
    "    \n",
    "    # assign majority class as default label\n",
    "    majority_class = Counter(gold_labels).most_common()[0][0]\n",
    "    rows_with_same_p1=np.where(np.all(p1 == 1/len(np.unique(gold_labels)), axis=1))[0]\n",
    "    rows_with_same_p2=np.where(np.all(p2 == 1/len(np.unique(gold_labels)), axis=1))[0]\n",
    "    if rows_with_same_p1.size > 0:\n",
    "        print(f'{rows_with_same_p1.size} system1 predictions substituted with majority_class')\n",
    "        pred1[rows_with_same_p1] = majority_class\n",
    "    if rows_with_same_p2.size > 0:\n",
    "        print(f'{rows_with_same_p2.size} system2 predictions substituted with majority_class')\n",
    "        pred2[rows_with_same_p2] = majority_class\n",
    "    \n",
    "    print('**********')\n",
    "\n",
    "    # compute acc of models 1 and 2\n",
    "    acc1 = accuracy_score(gold_labels, pred1)\n",
    "    acc2 = accuracy_score(gold_labels, pred2)\n",
    "\n",
    "    # compute f1 of models 1 and 2\n",
    "    f11 = f1_score(gold_labels, pred1, average=None)\n",
    "    f12 = f1_score(gold_labels, pred2, average=None)\n",
    "    \n",
    "    \n",
    "    if len(class_means) > 0:\n",
    "        total_error1 = 0\n",
    "        total_error2 = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error1 = abs(class_means[pred1[i]] - class_means[gold_labels[i]])\n",
    "            error2 = abs(class_means[pred2[i]] - class_means[gold_labels[i]])\n",
    "            total_error1 += error1\n",
    "            total_error2 += error2\n",
    "        mean_error1 = total_error1 / len(gold_labels)\n",
    "        mean_error2 = total_error2 / len(gold_labels)\n",
    "\n",
    "    print('System 1')\n",
    "    print('Ac:', acc1*100)\n",
    "    print('F1:', f11.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error1)\n",
    "    print('----------')\n",
    "    print('System 2')\n",
    "    print('Ac:', acc2*100)\n",
    "    print('F1:', f12.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error2)\n",
    "    print('----------')\n",
    "\n",
    "    # compute aggregated predictions\n",
    "    p_agg_1 = p1 + p2\n",
    "    pred_agg_1 = p_agg_1.argmax(axis=1)\n",
    "    acc_agg_1 = accuracy_score(gold_labels, pred_agg_1)\n",
    "    f1agg_1 = f1_score(gold_labels, pred_agg_1, average=None)\n",
    "    if len(class_means) > 0:\n",
    "        total_error = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error = abs(class_means[pred_agg_1[i]] - class_means[gold_labels[i]])\n",
    "            total_error += error\n",
    "        mean_error = total_error / len(gold_labels)\n",
    "    print('Avg prediction system ')\n",
    "    print('Ac:', acc_agg_1*100)\n",
    "    print('F1:', f1agg_1.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error)\n",
    "    print('----------')\n",
    "    \n",
    "    p_agg_2 = f11.mean()*p1 + f12.mean()*p2\n",
    "    pred_agg_2 = p_agg_2.argmax(axis=1)\n",
    "    acc_agg_2 = accuracy_score(gold_labels, pred_agg_2)\n",
    "    f1agg_2 = f1_score(gold_labels, pred_agg_2, average=None)\n",
    "    if len(class_means) > 0:\n",
    "        total_error = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error = abs(class_means[pred_agg_2[i]] - class_means[gold_labels[i]])\n",
    "            total_error += error\n",
    "        mean_error = total_error / len(gold_labels)\n",
    "    print('F1mean-weighted prediction system ')\n",
    "    print('Ac:', acc_agg_2*100)\n",
    "    print('F1:', f1agg_2.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error)\n",
    "    print('----------')\n",
    "\n",
    "    p_agg_3 = f11*p1 + f12*p2\n",
    "    pred_agg_3 = p_agg_3.argmax(axis=1)\n",
    "    acc_agg_3 = accuracy_score(gold_labels, pred_agg_3)\n",
    "    f1agg_3 = f1_score(gold_labels, pred_agg_3, average=None)\n",
    "    if len(class_means) > 0:\n",
    "        total_error = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error = abs(class_means[pred_agg_3[i]] - class_means[gold_labels[i]])\n",
    "            total_error += error\n",
    "        mean_error = total_error / len(gold_labels)\n",
    "    print('F1-weighted prediction system ')\n",
    "    print('Ac:', acc_agg_3*100)\n",
    "    print('F1:', f1agg_3.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error)\n",
    "    print('----------')\n",
    "    \n",
    "    return pred_agg_1, pred_agg_2, pred_agg_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608a153-ba7f-4b0b-8470-2b6986c81208",
   "metadata": {},
   "source": [
    "# DE gender XLM+M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e55bac30-5848-4e64-bc62-3f7738098173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 290, 1: 94})\n",
      "Counter({0: 365, 1: 19})\n",
      "**********\n",
      "System 1\n",
      "Ac: 81.77083333333334\n",
      "F1: 74.2014742014742\n",
      "----------\n",
      "System 2\n",
      "Ac: 79.94791666666666\n",
      "F1: 56.10907417578339\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 84.375\n",
      "F1: 75.39302802460699\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 83.59375\n",
      "F1: 74.7808229174268\n",
      "----------\n",
      "F1-weighted prediction system \n",
      "Ac: 85.15625\n",
      "F1: 69.98642478094533\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.array(xlm_de[['prob_male','prob_female']])\n",
    "p2 = np.array(m3_de[['m3_prob_male','m3_prob_female']])\n",
    "\n",
    "gold_labels = (~(test_set.is_male).astype(bool)).astype(int)\n",
    "\n",
    "gender_pred_agg_avg, gender_pred_agg_f1mean, _ = aggregate_performace(p1, p2, gold_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465b81f-3693-4e1d-b578-e83af2634577",
   "metadata": {},
   "source": [
    "# DE age XLM+M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fc0d819-d7ab-4d42-982c-259e4e29a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 195, 1: 107, 0: 51, 2: 31})\n",
      "Counter({0: 233, 1: 63, 3: 54, 2: 34})\n",
      "**********\n",
      "System 1\n",
      "Ac: 56.25\n",
      "F1: 43.65400144936413\n",
      "----------\n",
      "System 2\n",
      "Ac: 34.11458333333333\n",
      "F1: 27.36473214285714\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 60.416666666666664\n",
      "F1: 49.0437030226263\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 58.854166666666664\n",
      "F1: 48.13972978652393\n",
      "----------\n",
      "F1-weighted prediction system \n",
      "Ac: 62.239583333333336\n",
      "F1: 43.78739730830527\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.array(xlm_de[['prob_0_18', 'prob_19_29', 'prob_30_39', 'prob_40_100']])\n",
    "p2 = np.array(m3_de[['m3_prob_0_18','m3_prob_19_29','m3_prob_30_39','m3_prob_40_100']])\n",
    "\n",
    "_ , gold_labels = twitter_features(test_set, label_name='age_interval')\n",
    "\n",
    "age_pred_agg_avg, age_pred_agg_f1mean, _ = aggregate_performace(\n",
    "    p1,\n",
    "    p2,\n",
    "    gold_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbb9aca1-27a4-4cfe-8996-831b1c119f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 1, 3, 3, 3, 3, 2, 3, 0, 3, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 0,\n",
       "       1, 3, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 3, 3, 3, 3, 3, 1, 2, 3, 1,\n",
       "       3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 1, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3,\n",
       "       3, 3, 3, 3, 3, 2, 3, 3, 3, 0, 3, 3, 3, 3, 1, 1, 1, 2, 1, 1, 3, 3,\n",
       "       3, 3, 3, 3, 0, 3, 2, 2, 1, 2, 2, 1, 3, 1, 2, 2, 3, 3, 1, 2, 0, 1,\n",
       "       3, 2, 3, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 2, 1, 2, 1, 3, 1, 1, 3,\n",
       "       1, 1, 3, 0, 1, 0, 0, 3, 3, 0, 3, 1, 3, 3, 0, 3, 3, 1, 1, 3, 3, 3,\n",
       "       3, 1, 3, 1, 1, 3, 1, 1, 3, 1, 3, 3, 3, 3, 0, 3, 3, 3, 1, 0, 3, 3,\n",
       "       0, 3, 3, 3, 3, 3, 0, 1, 0, 3, 0, 3, 3, 3, 0, 3, 0, 3, 3, 3, 1, 3,\n",
       "       3, 3, 0, 3, 3, 1, 3, 2, 3, 3, 3, 3, 3, 0, 3, 1, 3, 3, 1, 3, 1, 3,\n",
       "       1, 3, 1, 3, 1, 0, 3, 3, 1, 0, 0, 0, 1, 1, 1, 0, 1, 3, 0, 0, 0, 3,\n",
       "       3, 0, 0, 0, 2, 0, 0, 3, 1, 0, 3, 0, 1, 3, 1, 3, 0, 0, 1, 1, 3, 3,\n",
       "       0, 0, 0, 0, 0, 1, 1, 2, 0, 3, 1, 3, 0, 0, 0, 3, 3, 1, 1, 2, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 3, 3, 1, 1, 3, 1, 1, 1, 0, 0, 0, 0, 3, 2, 0,\n",
       "       0, 1, 1, 1, 3, 1, 0, 3, 2, 1, 3, 3, 1, 0, 1, 0, 1, 1, 1, 3, 3, 2,\n",
       "       0, 3, 0, 0, 3, 0, 1, 3, 3, 1, 1, 3, 3, 3, 0, 0, 0, 3, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 3, 3, 1, 1, 0, 0, 1, 0, 3, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 3, 0, 0, 3, 0, 0, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_pred_agg_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f78fc4b-8c3c-4268-9d9a-4dce071c49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"user_id\": test_set.user_id,\n",
    "        \"gender_avg_agg\": gender_pred_agg_avg,\n",
    "        \"gender_f1_agg\": gender_pred_agg_f1mean,\n",
    "        \"age_avg_agg\": age_pred_agg_avg,\n",
    "        \"age_f1_agg\": age_pred_agg_f1mean\n",
    "    }\n",
    ").to_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/de/xlm_m3_untrained_agg_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d3a94d-163d-43ab-aab8-885a6236cc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASK 2022.10 (Python 3.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
