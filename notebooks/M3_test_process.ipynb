{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8567bc3f-dee5-418c-95db-fb5988ceea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 00:26:28 - INFO - m3inference.m3inference -   Version 1.1.5\n",
      "10/14/2023 00:26:28 - INFO - m3inference.m3inference -   Running on cuda.\n",
      "10/14/2023 00:26:28 - INFO - m3inference.m3inference -   Will use full M3 model.\n",
      "10/14/2023 00:26:29 - INFO - m3inference.m3inference -   Model full_model exists at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl.\n",
      "10/14/2023 00:26:29 - INFO - m3inference.utils -   Checking MD5 for model full_model at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl\n",
      "10/14/2023 00:26:30 - INFO - m3inference.utils -   MD5s match.\n",
      "10/14/2023 00:26:37 - INFO - m3inference.m3inference -   Loaded pretrained weight at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from m3inference import M3Inference\n",
    "from m3inference import M3Twitter\n",
    "import pprint\n",
    "from langdetect import detect\n",
    "import time\n",
    "m3 = M3Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1dc183-bc00-47b5-ad2a-693178c4775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/g100/home/userexternal/mhabibi0/'\n",
    "work_dir = '/g100_work/IscrC_mental'\n",
    "\n",
    "hdata_dir = os.path.join(home_dir, 'Data')\n",
    "wdata_dir = os.path.join(work_dir, 'data')\n",
    "uc_dir = os.path.join(wdata_dir, 'user_classification')\n",
    "\n",
    "\n",
    "wimg_dir = os.path.join(uc_dir, 'images')\n",
    "wimg_test_dir = os.path.join(wimg_dir, 'test')\n",
    "wimg_train_dir = os.path.join(wimg_dir, 'train')\n",
    "wimg_de_dir = os.path.join(wimg_dir, 'de')\n",
    "\n",
    "himg_dir = os.path.join(hdata_dir, 'images')\n",
    "himg_test_dir = os.path.join(himg_dir, 'test')\n",
    "himg_train_dir = os.path.join(himg_dir, 'train')\n",
    "himg_de_dir = os.path.join(himg_dir, 'de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a069cf-d4f0-4425-bc22-dee1bfa496b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['preprocess.py', 'de', 'train', 'test']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(himg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcb11b4-9855-489d-afd9-861680821f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy test images to home\n",
    "\n",
    "# himage_dir =os.path.join(hdata_dir, 'images', 'test')\n",
    "# shutil.copytree(image_dir, himage_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3724c4-3597-48de-a088-c257f265ca1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/g100/home/userexternal/mhabibi0/Data/images/de'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy train images to home\n",
    "#shutil.copytree(wimg_test_dir, himg_test_dir)\n",
    "shutil.copytree(wimg_train_dir, himg_train_dir)\n",
    "shutil.copytree(wimg_de_dir, himg_de_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ed898f9-ff78-4b5d-8886-b099b8e3d589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/g100/home/userexternal/mhabibi0/Data/images\n"
     ]
    }
   ],
   "source": [
    "# resize images \n",
    "%cd /g100/home/userexternal/mhabibi0/Data/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6812d3d-6ef4-4958-bd3a-518ded63e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocess.py --source_dir /g100/home/userexternal/mhabibi0/Data/images/test/ --output_dir /g100/home/userexternal/mhabibi0/Data/images/test/images_resized_v2/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43043225-c1b5-427e-b249-efbce5a3cbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python preprocess.py --source_dir /g100/home/userexternal/mhabibi0/Data/images/train/ --output_dir /g100/home/userexternal/mhabibi0/Data/images/train/images_resized/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb84e3eb-367e-488d-bf8a-8c75bb04b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python preprocess.py --source_dir /g100/home/userexternal/mhabibi0/Data/images/de/ --output_dir /g100/home/userexternal/mhabibi0/Data/images/de/images_resized/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f49d909-4996-44cd-af0c-47ce7f3654a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio lang\n",
    "def detect_lang(bio_text):\n",
    "    # languages that M3 supports\n",
    "    list_langs = ['en', 'cs', 'fr', 'nl', 'ar', 'ro', 'bs', 'da', 'it', 'pt', 'no',\n",
    "                  'es', 'hr', 'tr', 'de', 'fi', 'el', 'ru', 'bg', 'hu', 'sk', 'et', \n",
    "                  'pl', 'lv', 'sl', 'lt', 'ga', 'eu', 'mt', 'cy', 'rm', 'is', 'un']\n",
    "\n",
    "    try:\n",
    "        lang = detect(bio_text)\n",
    "    except Exception as e:\n",
    "        lang = 'it'  # default to 'it' in case of exceptions\n",
    "\n",
    "    # if not supported by M3\n",
    "    if lang not in list_langs:\n",
    "        lang = 'it'\n",
    "    \n",
    "    return lang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51652059-632f-47ea-808d-bead7412a4b9",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445d5d59-123d-4fb9-b5a1-b4a63fe62230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user age data\n",
    "path  = os.path.join(uc_dir, 'data_for_models_test.pkl')\n",
    "df_test = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd095cde-c512-4809-895f-180e63bee7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10984468/ipykernel_40907/2849860590.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n",
      "/scratch_local/slurm_job.10984468/ipykernel_40907/2849860590.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "img_dir = os.path.join(himg_test_dir, 'images_resized')\n",
    "# path to image\n",
    "df_m3 = df_test[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n",
    "\n",
    "# check if processed image exists\n",
    "id_image_paths = df_m3['img_path'].values.tolist()\n",
    "nonexist_paths_resized = [path for path in id_image_paths if not os.path.exists(path)]\n",
    "nonexisting_ids = [path.split('/')[-1].split('.jpeg')[0] for path in nonexist_paths_resized]\n",
    "\n",
    "# filter to ids having image\n",
    "df_m3 = df_m3[~ df_m3['id'].isin(nonexisting_ids)]\n",
    "\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b78da07-f00c-4480-a118-46f0c954b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fbe474-b5b6-4e0d-887d-915c7a9aa53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the image\n",
    "# uid = nonexist_ids[7]+'.jpg'\n",
    "# image_path = os.path.join(himage_dir, uid)\n",
    "# img = Image.open(image_path)\n",
    "\n",
    "# # Display the image\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')  # To turn off axis numbers and ticks\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e388817-15cb-4f59-8e62-6a09674e25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 00:53:26 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]\n",
      "10/14/2023 00:53:30 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.12it/s]\n",
      "10/14/2023 00:53:31 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.45it/s]\n",
      "10/14/2023 00:53:31 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.31it/s]\n",
      "10/14/2023 00:53:32 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.72it/s]\n",
      "10/14/2023 00:53:32 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.53it/s]\n",
      "10/14/2023 00:53:33 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.40it/s]\n",
      "10/14/2023 00:53:34 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]\n",
      "10/14/2023 00:53:34 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.28it/s]\n",
      "10/14/2023 00:53:35 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.88it/s]\n",
      "10/14/2023 00:53:35 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.72it/s]\n",
      "10/14/2023 00:53:36 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "10/14/2023 00:53:36 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.87it/s]\n",
      "10/14/2023 00:53:37 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.75it/s]\n",
      "10/14/2023 00:53:37 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]\n",
      "10/14/2023 00:53:38 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.75it/s]\n",
      "10/14/2023 00:53:38 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.00it/s]\n",
      "10/14/2023 00:53:39 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.83it/s]\n",
      "10/14/2023 00:53:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.85it/s]\n",
      "10/14/2023 00:53:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.33it/s]\n",
      "10/14/2023 00:53:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "10/14/2023 00:53:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "10/14/2023 00:53:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.78it/s]\n",
      "10/14/2023 00:53:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.84it/s]\n",
      "10/14/2023 00:53:43 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.41it/s]\n",
      "10/14/2023 00:53:43 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.65it/s]\n",
      "10/14/2023 00:53:44 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "10/14/2023 00:53:44 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.69it/s]\n",
      "10/14/2023 00:53:45 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.08it/s]\n",
      "10/14/2023 00:53:45 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]\n",
      "10/14/2023 00:53:46 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]\n",
      "10/14/2023 00:53:46 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.13it/s]\n",
      "10/14/2023 00:53:47 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.32it/s]\n",
      "10/14/2023 00:53:47 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.99it/s]\n",
      "10/14/2023 00:53:48 - INFO - m3inference.dataset -   19 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the results\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "results = OrderedDict()\n",
    "\n",
    "# Process data_json in batches\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results.update(result_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16c7588b-438a-413a-8865-ed907e771443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "path = os.path.join(uc_dir, 'M3_results_test_bio_image.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db82caa7-e693-49c5-a7fe-b7ebc7df3fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d970742-4d64-4e5e-a5a8-7acdf8e9535a",
   "metadata": {},
   "source": [
    "#### Bio only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35e1b997-e639-4833-99f8-48f2827f2abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10984468/ipykernel_40907/762466409.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "\n",
    "df_m3 = df_test[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "\n",
    "# remove cases with no bios\n",
    "df_m3 = df_m3[ df_m3['description']!='']\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6012a4-7aae-4591-8236-a2eb72a685d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 00:54:51 - INFO - m3inference.m3inference -   Version 1.1.5\n",
      "10/14/2023 00:54:51 - INFO - m3inference.m3inference -   Running on cuda.\n",
      "10/14/2023 00:54:51 - INFO - m3inference.m3inference -   Will use text model. Note that as M3 was optimized to work well with both image and text data,                                     it is not recommended to use text only model unless you do not have the profile image.\n",
      "10/14/2023 00:54:51 - INFO - m3inference.m3inference -   Model text_model exists at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl.\n",
      "10/14/2023 00:54:51 - INFO - m3inference.utils -   Checking MD5 for model text_model at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl\n",
      "10/14/2023 00:54:51 - INFO - m3inference.utils -   MD5s match.\n",
      "10/14/2023 00:54:51 - INFO - m3inference.m3inference -   Loaded pretrained weight at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl\n",
      "10/14/2023 00:54:51 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.22it/s]\n",
      "10/14/2023 00:54:51 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.31it/s]\n",
      "10/14/2023 00:54:51 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.19it/s]\n",
      "10/14/2023 00:54:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.32it/s]\n",
      "10/14/2023 00:54:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.26it/s]\n",
      "10/14/2023 00:54:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.17it/s]\n",
      "10/14/2023 00:54:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.24it/s]\n",
      "10/14/2023 00:54:53 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.28it/s]\n",
      "10/14/2023 00:54:53 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.14it/s]\n",
      "10/14/2023 00:54:53 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.22it/s]\n",
      "10/14/2023 00:54:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.18it/s]\n",
      "10/14/2023 00:54:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.16it/s]\n",
      "10/14/2023 00:54:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.30it/s]\n",
      "10/14/2023 00:54:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.31it/s]\n",
      "10/14/2023 00:54:55 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.11it/s]\n",
      "10/14/2023 00:54:55 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  7.31it/s]\n",
      "10/14/2023 00:54:55 - INFO - m3inference.dataset -   7 data entries loaded.\n",
      "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process data_json in batches\n",
    "results_bio_only = OrderedDict()\n",
    "m3 = M3Inference(use_full_model=False)\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results_bio_only.update(result_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ad74e75-914f-4b20-81da-c48f7d016c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_keys = list(results_bio_only.keys())\n",
    "len(list_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d57bc98c-2cd9-4d9c-9cdb-52d0a00690aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "path = os.path.join(uc_dir, 'M3_results_test_bio_only.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results_bio_only, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbee937-e601-4796-922f-534419570125",
   "metadata": {},
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b508e8d-465a-42d4-ab48-1d15068d6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user age data\n",
    "path  = os.path.join(uc_dir, 'data_for_models_train.pkl')\n",
    "df_train = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21ed4cbe-7b28-4e44-9868-d5ca8e5bf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10984468/ipykernel_40907/2727949520.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n",
      "/scratch_local/slurm_job.10984468/ipykernel_40907/2727949520.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "img_dir = os.path.join(himg_train_dir, 'images_resized')\n",
    "# path to image\n",
    "df_m3 = df_train[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n",
    "\n",
    "# check if processed image exists\n",
    "id_image_paths = df_m3['img_path'].values.tolist()\n",
    "nonexist_paths_resized = [path for path in id_image_paths if not os.path.exists(path)]\n",
    "nonexisting_ids = [path.split('/')[-1].split('.jpeg')[0] for path in nonexist_paths_resized]\n",
    "\n",
    "# filter to ids having image\n",
    "df_m3 = df_m3[~ df_m3['id'].isin(nonexisting_ids)]\n",
    "\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a5fb850-dc9e-4749-907d-bad93fd18532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15337"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d9d9c9-6e98-4282-bc86-57d294172dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the results\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "results = OrderedDict()\n",
    "\n",
    "# Process data_json in batches\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results.update(result_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bc03976-9a1a-4d51-acb4-89f8b52c2397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15337"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "562ee256-8fc1-4095-a4a6-5151808f18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "path = os.path.join(uc_dir, 'M3_results_train_bio_image.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17d644-b549-4061-9e46-939a6312f90a",
   "metadata": {},
   "source": [
    "## German Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63c3c563-a765-4164-a1ea-01d1d3d77377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_for_models_german_data.pkl',\n",
       " 'german_tweets.pkl',\n",
       " 'german_users_with_birthyear.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(uc_dir, 'german_data')\n",
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74ea28f3-f232-4614-8ace-da4be8ca9e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user age data\n",
    "path  = os.path.join(uc_dir, 'german_data', 'data_for_models_german_data.pkl')\n",
    "df_de = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c23b0a83-f099-4d89-8ee1-5dbbd8b1c11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10984468/ipykernel_40907/290704806.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n",
      "/scratch_local/slurm_job.10984468/ipykernel_40907/290704806.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "img_dir = os.path.join(himg_de_dir, 'images_resized')\n",
    "# path to image\n",
    "df_m3 = df_de[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n",
    "\n",
    "# check if processed image exists\n",
    "id_image_paths = df_m3['img_path'].values.tolist()\n",
    "nonexist_paths_resized = [path for path in id_image_paths if not os.path.exists(path)]\n",
    "nonexisting_ids = [path.split('/')[-1].split('.jpeg')[0] for path in nonexist_paths_resized]\n",
    "\n",
    "# filter to ids having image\n",
    "df_m3 = df_m3[~ df_m3['id'].isin(nonexisting_ids)]\n",
    "\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86f55723-b2dd-4182-9583-815a24ce0600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adfb5efc-f351-4187-b0d3-8d8238353d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/14/2023 01:13:38 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]\n",
      "10/14/2023 01:13:39 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]\n",
      "10/14/2023 01:13:39 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.53it/s]\n",
      "10/14/2023 01:13:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "10/14/2023 01:13:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]\n",
      "10/14/2023 01:13:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "10/14/2023 01:13:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]\n",
      "10/14/2023 01:13:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]\n",
      "10/14/2023 01:13:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.50it/s]\n",
      "10/14/2023 01:13:43 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.61it/s]\n",
      "10/14/2023 01:13:44 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.51it/s]\n",
      "10/14/2023 01:13:44 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]\n",
      "10/14/2023 01:13:45 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]\n",
      "10/14/2023 01:13:45 - INFO - m3inference.dataset -   4 data entries loaded.\n",
      "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the results\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "results = OrderedDict()\n",
    "\n",
    "# Process data_json in batches\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results.update(result_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04ec5224-dab2-413c-b037-46011aad0157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4880f89a-6909-4c7a-9098-8a2ec3e4a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "path = os.path.join(uc_dir, 'M3_results_de_bio_image.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 1.12.1 (Python 3.10)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
