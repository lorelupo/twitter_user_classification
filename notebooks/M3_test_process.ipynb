{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8567bc3f-dee5-418c-95db-fb5988ceea2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/11/2023 23:08:59 - INFO - m3inference.m3inference -   Version 1.1.5\n",
      "10/11/2023 23:08:59 - INFO - m3inference.m3inference -   Running on cuda.\n",
      "10/11/2023 23:08:59 - INFO - m3inference.m3inference -   Will use full M3 model.\n",
      "10/11/2023 23:09:00 - INFO - m3inference.m3inference -   Model full_model exists at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl.\n",
      "10/11/2023 23:09:00 - INFO - m3inference.utils -   Checking MD5 for model full_model at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl\n",
      "10/11/2023 23:09:00 - INFO - m3inference.utils -   MD5s match.\n",
      "10/11/2023 23:09:13 - INFO - m3inference.m3inference -   Loaded pretrained weight at /g100/home/userexternal/mhabibi0/m3/models/full_model.mdl\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from m3inference import M3Inference\n",
    "from m3inference import M3Twitter\n",
    "import pprint\n",
    "from langdetect import detect\n",
    "import time\n",
    "m3 = M3Inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1dc183-bc00-47b5-ad2a-693178c4775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/g100/home/userexternal/mhabibi0/'\n",
    "work_dir = '/g100_work/IscrC_mental'\n",
    "\n",
    "hdata_dir = os.path.join(home_dir, 'Data')\n",
    "wdata_dir = os.path.join(work_dir, 'data')\n",
    "uc_dir = os.path.join(wdata_dir, 'user_classification')\n",
    "image_dir = os.path.join(uc_dir, 'images', 'test')\n",
    "himage_dir =os.path.join(hdata_dir, 'images', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcb11b4-9855-489d-afd9-861680821f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy images to home\n",
    "\n",
    "# himage_dir =os.path.join(hdata_dir, 'images', 'test')\n",
    "# shutil.copytree(image_dir, himage_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed898f9-ff78-4b5d-8886-b099b8e3d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resize images \n",
    "# %cd /g100/home/userexternal/mhabibi0/Data/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6812d3d-6ef4-4958-bd3a-518ded63e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python preprocess.py --source_dir /g100/home/userexternal/mhabibi0/Data/images/test/ --output_dir /g100/home/userexternal/mhabibi0/Data/images/test/images_resized_v2/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909e2b0f-b140-4f70-9c07-cd1225c03b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgres_dir = os.path.join(himage_dir, 'images_resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "445d5d59-123d-4fb9-b5a1-b4a63fe62230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user age data\n",
    "path  = os.path.join(uc_dir, 'data_for_models_test.pkl')\n",
    "df_test = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87110f24-1501-4b77-a4ed-f3d8d5d8d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bio lang\n",
    "def detect_lang(bio_text):\n",
    "    # languages that M3 supports\n",
    "    list_langs = ['en', 'cs', 'fr', 'nl', 'ar', 'ro', 'bs', 'da', 'it', 'pt', 'no',\n",
    "                  'es', 'hr', 'tr', 'de', 'fi', 'el', 'ru', 'bg', 'hu', 'sk', 'et', \n",
    "                  'pl', 'lv', 'sl', 'lt', 'ga', 'eu', 'mt', 'cy', 'rm', 'is', 'un']\n",
    "\n",
    "    try:\n",
    "        lang = detect(bio_text)\n",
    "    except Exception as e:\n",
    "        lang = 'it'  # default to 'it' in case of exceptions\n",
    "\n",
    "    # if not supported by M3\n",
    "    if lang not in list_langs:\n",
    "        lang = 'it'\n",
    "    \n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd095cde-c512-4809-895f-180e63bee7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10955448/ipykernel_3813088/1080182451.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n",
      "/scratch_local/slurm_job.10955448/ipykernel_3813088/1080182451.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "img_dir = os.path.join(himage_dir, 'images_resized')\n",
    "# path to image\n",
    "df_m3 = df_test[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "df_m3['img_path'] = df_m3['id'].apply(lambda x: os.path.join(img_dir, str(x)+'.jpeg'))\n",
    "\n",
    "# check if processed image exists\n",
    "id_image_paths = df_m3['img_path'].values.tolist()\n",
    "nonexist_paths_resized = [path for path in id_image_paths if not os.path.exists(path)]\n",
    "nonexisting_ids = [path.split('/')[-1].split('.jpeg')[0] for path in nonexist_paths_resized]\n",
    "\n",
    "# filter to ids having image\n",
    "df_m3 = df_m3[~ df_m3['id'].isin(nonexisting_ids)]\n",
    "\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b78da07-f00c-4480-a118-46f0c954b786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fbe474-b5b6-4e0d-887d-915c7a9aa53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the image\n",
    "# uid = nonexist_ids[7]+'.jpg'\n",
    "# image_path = os.path.join(himage_dir, uid)\n",
    "# img = Image.open(image_path)\n",
    "\n",
    "# # Display the image\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')  # To turn off axis numbers and ticks\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e388817-15cb-4f59-8e62-6a09674e25c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/11/2023 23:09:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n",
      "10/11/2023 23:09:47 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.14it/s]\n",
      "10/11/2023 23:09:47 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]\n",
      "10/11/2023 23:09:48 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.89it/s]\n",
      "10/11/2023 23:09:48 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.04it/s]\n",
      "10/11/2023 23:09:49 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.04it/s]\n",
      "10/11/2023 23:09:49 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.27it/s]\n",
      "10/11/2023 23:09:50 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.97it/s]\n",
      "10/11/2023 23:09:50 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.96it/s]\n",
      "10/11/2023 23:09:51 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.25it/s]\n",
      "10/11/2023 23:09:51 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.31it/s]\n",
      "10/11/2023 23:09:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]\n",
      "10/11/2023 23:09:52 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  3.93it/s]\n",
      "10/11/2023 23:09:53 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.28it/s]\n",
      "10/11/2023 23:09:53 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.17it/s]\n",
      "10/11/2023 23:09:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]\n",
      "10/11/2023 23:09:54 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.12it/s]\n",
      "10/11/2023 23:09:55 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.40it/s]\n",
      "10/11/2023 23:09:55 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.33it/s]\n",
      "10/11/2023 23:09:55 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.33it/s]\n",
      "10/11/2023 23:09:56 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.27it/s]\n",
      "10/11/2023 23:09:56 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.42it/s]\n",
      "10/11/2023 23:09:57 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.37it/s]\n",
      "10/11/2023 23:09:57 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.40it/s]\n",
      "10/11/2023 23:09:58 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.30it/s]\n",
      "10/11/2023 23:09:58 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.10it/s]\n",
      "10/11/2023 23:09:59 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.28it/s]\n",
      "10/11/2023 23:09:59 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.41it/s]\n",
      "10/11/2023 23:10:00 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.47it/s]\n",
      "10/11/2023 23:10:00 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.26it/s]\n",
      "10/11/2023 23:10:01 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.37it/s]\n",
      "10/11/2023 23:10:01 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.44it/s]\n",
      "10/11/2023 23:10:01 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.24it/s]\n",
      "10/11/2023 23:10:02 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.21it/s]\n",
      "10/11/2023 23:10:02 - INFO - m3inference.dataset -   19 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the results\n",
    "from collections import OrderedDict\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "results = OrderedDict()\n",
    "\n",
    "# Process data_json in batches\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results.update(result_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16c7588b-438a-413a-8865-ed907e771443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "\n",
    "path = os.path.join(uc_dir, 'M3_results_test_bio_image.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db82caa7-e693-49c5-a7fe-b7ebc7df3fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d970742-4d64-4e5e-a5a8-7acdf8e9535a",
   "metadata": {},
   "source": [
    "## Bio only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35e1b997-e639-4833-99f8-48f2827f2abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10950248/ipykernel_14161/762466409.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m3['id'] = df_m3['id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# transform the data to match M3 standard input\n",
    "\n",
    "df_m3 = df_test[['user_id', 'masked_bio']]\n",
    "df_m3.columns = ['id', 'description']\n",
    "df_m3['id'] = df_m3['id'].astype(str)\n",
    "\n",
    "# remove cases with no bios\n",
    "df_m3 = df_m3[ df_m3['description']!='']\n",
    "# bio language\n",
    "df_m3['lang'] = df_m3['description'].map(detect_lang)\n",
    "\n",
    "df_m3['name'] = ''\n",
    "df_m3['screen_name'] = ''\n",
    "\n",
    "data_json = df_m3.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6012a4-7aae-4591-8236-a2eb72a685d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/11/2023 20:15:32 - INFO - m3inference.m3inference -   Version 1.1.5\n",
      "10/11/2023 20:15:32 - INFO - m3inference.m3inference -   Running on cuda.\n",
      "10/11/2023 20:15:32 - INFO - m3inference.m3inference -   Will use text model. Note that as M3 was optimized to work well with both image and text data,                                     it is not recommended to use text only model unless you do not have the profile image.\n",
      "10/11/2023 20:15:32 - INFO - m3inference.m3inference -   Model text_model does not exist at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl. Try to download it now.\n",
      "10/11/2023 20:15:32 - INFO - m3inference.utils -   /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl not found in cache, downloading from https://nlp.stanford.edu/~zijwang/m3inference/text_model.mdl to /scratch_local/slurm_job.10950248/tmpry9dsq2f\n",
      "31589KB [00:05, 5504.71KB/s]                            \n",
      "10/11/2023 20:15:39 - INFO - m3inference.utils -   Model text_model was downloaded to a tmp file.\n",
      "10/11/2023 20:15:39 - INFO - m3inference.utils -   Copying tmp file to /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl.\n",
      "10/11/2023 20:15:39 - INFO - m3inference.utils -   Copied tmp model file to /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl.\n",
      "10/11/2023 20:15:39 - INFO - m3inference.utils -   Checking MD5 for model text_model at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl\n",
      "10/11/2023 20:15:39 - INFO - m3inference.utils -   MD5s match.\n",
      "10/11/2023 20:15:39 - INFO - m3inference.m3inference -   Loaded pretrained weight at /g100/home/userexternal/mhabibi0/m3/models/text_model.mdl\n",
      "10/11/2023 20:15:39 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  8.14it/s]\n",
      "10/11/2023 20:15:39 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.37it/s]\n",
      "10/11/2023 20:15:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.32it/s]\n",
      "10/11/2023 20:15:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.41it/s]\n",
      "10/11/2023 20:15:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.29it/s]\n",
      "10/11/2023 20:15:40 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.25it/s]\n",
      "10/11/2023 20:15:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.32it/s]\n",
      "10/11/2023 20:15:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.33it/s]\n",
      "10/11/2023 20:15:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.35it/s]\n",
      "10/11/2023 20:15:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.42it/s]\n",
      "10/11/2023 20:15:41 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.32it/s]\n",
      "10/11/2023 20:15:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.28it/s]\n",
      "10/11/2023 20:15:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.40it/s]\n",
      "10/11/2023 20:15:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.39it/s]\n",
      "10/11/2023 20:15:42 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.31it/s]\n",
      "10/11/2023 20:15:43 - INFO - m3inference.dataset -   32 data entries loaded.\n",
      "Predicting...: 100%|██████████| 2/2 [00:00<00:00,  9.43it/s]\n",
      "10/11/2023 20:15:43 - INFO - m3inference.dataset -   7 data entries loaded.\n",
      "Predicting...: 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process data_json in batches\n",
    "results_bio_only = OrderedDict()\n",
    "m3 = M3Inference(use_full_model=False)\n",
    "for i in range(0, len(data_json), batch_size):\n",
    "    batch = data_json[i:i+batch_size]\n",
    "    result_batch = m3.infer(batch)\n",
    "    results_bio_only.update(result_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ad74e75-914f-4b20-81da-c48f7d016c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_keys = list(results_bio_only.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d57bc98c-2cd9-4d9c-9cdb-52d0a00690aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "path = os.path.join(uc_dir, 'M3_results_test_bio_only.json')\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(results_bio_only, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffc147-8513-4344-9822-2823b9a2f655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 1.12.1 (Python 3.10)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
