{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "478ab7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c18745ba-bfae-4bb4-8ff4-45e6f1559774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xlm_ita_age_train = pd.DataFrame(np.load('/g100_work/IscrC_mental/data/user_classification/trained_models/age/XLM_probs_age_traind.npy')\n",
    "#xlm_ita_gender_train = pd.DataFrame(np.load('/g100_work/IscrC_mental/data/user_classification/trained_models/gender/XLM_probs_gender_train.npy')\n",
    "\n",
    "xlm_ita_gender = pd.DataFrame(np.load('/g100_work/IscrC_mental/data/user_classification/trained_models/gender/XLM_probs_gender_test.npy'))\n",
    "xlm_ita_gender.columns = ['user_id', 'p_is_female', 'p_is_male']\n",
    "xlm_ita_gender.user_id = xlm_ita_gender.user_id.astype(float)\n",
    "\n",
    "xlm_ita_age = pd.DataFrame(np.load('/g100_work/IscrC_mental/data/user_classification/trained_models/age/XLM_probs_age_test.npy'))\n",
    "xlm_ita_age.columns = ['user_id', 'pred_age_0_19_prob', 'pred_age_20_29_prob', 'pred_age_30_39_prob', 'pred_age_40_100_prob']\n",
    "xlm_ita_age.user_id = xlm_ita_age.user_id.astype(float)\n",
    "\n",
    "m3_it = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/m3_scores_bio_image.pkl')\n",
    "\n",
    "cv_it = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models.pkl')\n",
    "cv_it.user_id = cv_it.user_id.astype(float)\n",
    "\n",
    "cv_de = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/german_age_and_gender.pkl')\n",
    "\n",
    "test_set = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/data_for_models_test.pkl')\n",
    "test_set.user_id = test_set.user_id.astype(float)\n",
    "\n",
    "\n",
    "# remove extra instances from datasets\n",
    "#xlm_ita_gender = test_set.merge(xlm_ita_gender, on='user_id', how='inner')\n",
    "xlm_ita_age = test_set.merge(xlm_ita_age, on='user_id', how='inner')\n",
    "m3_it = test_set.merge(m3_it, on='user_id', how='inner')\n",
    "cv_it = test_set.merge(cv_it, on='user_id', how='inner')\n",
    "# add missing rows in m3\n",
    "m3_it = test_set.merge(m3_it, on='user_id', how='outer')\n",
    "m3_it.loc[m3_it['score_male'].isna(), 'score_male'] = 0.5\n",
    "m3_it.loc[m3_it['score_female'].isna(), 'score_female'] = 0.5\n",
    "m3_it.loc[m3_it['score_age_cls_0'].isna(), 'score_age_cls_0'] = 0.25\n",
    "m3_it.loc[m3_it['score_age_cls_0'].isna(), 'score_age_cls_0'] = 0.25\n",
    "m3_it.loc[m3_it['score_age_cls_1'].isna(), 'score_age_cls_1'] = 0.25\n",
    "m3_it.loc[m3_it['score_age_cls_2'].isna(), 'score_age_cls_2'] = 0.25\n",
    "m3_it.loc[m3_it['score_age_cls_3'].isna(), 'score_age_cls_3'] = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "469c56e0-6ffb-4a15-8119-733bb4b05b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique User IDs in 'test_set':\n",
      "0\n",
      "Unique User IDs in 'xlm_ita_gender':\n",
      "0\n",
      "All unique User IDs: 0\n",
      "All unique User IDs: 1119\n",
      "All unique User IDs: 1119\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'test_set' and 'xlm_ita_gender' are your DataFrames\n",
    "test_set_user_ids = set(test_set['user_id'].astype(float))\n",
    "xlm_ita_gender_user_ids = set(xlm_ita_gender['user_id'].astype(float))\n",
    "\n",
    "# Find user IDs unique to 'test_set'\n",
    "unique_to_test_set = test_set_user_ids.difference(xlm_ita_gender_user_ids)\n",
    "\n",
    "# Find user IDs unique to 'xlm_ita_gender'\n",
    "unique_to_xlm_ita_gender = xlm_ita_gender_user_ids.difference(test_set_user_ids)\n",
    "\n",
    "# Combine the unique user IDs from both datasets\n",
    "all_unique_user_ids = unique_to_test_set.union(unique_to_xlm_ita_gender)\n",
    "\n",
    "# Create DataFrames with the unique user IDs\n",
    "unique_test_set_df = test_set[test_set['user_id'].isin(unique_to_test_set)]\n",
    "unique_xlm_ita_gender_df = xlm_ita_gender[xlm_ita_gender['user_id'].isin(unique_to_xlm_ita_gender)]\n",
    "\n",
    "# Print the DataFrames containing unique user IDs\n",
    "print(\"Unique User IDs in 'test_set':\")\n",
    "print(len(unique_to_test_set))\n",
    "print(\"Unique User IDs in 'xlm_ita_gender':\")\n",
    "print(len(unique_to_xlm_ita_gender))\n",
    "print(\"All unique User IDs:\", len(all_unique_user_ids))\n",
    "print(\"All unique User IDs:\", len(set(test_set['user_id'].astype(int))))\n",
    "print(\"All unique User IDs:\", len(set(xlm_ita_gender['user_id'].astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e4a1e31c-92c0-4d03-b789-90c350c36824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_features(\n",
    "    df,\n",
    "    include_bio=True,\n",
    "    include_tweets=True,\n",
    "    label_name='is_male',\n",
    "    ):\n",
    "    # check if there are any missing values (shouldn't be the case)\n",
    "    if df.isnull().values.any():\n",
    "        raise ValueError('The dataframe contains missing values')\n",
    "    # Read each bio and tweets concatenation, splitting them by \\n and\n",
    "    # joining by '. ' if sentences don't already end with a dot, else join by ' '\n",
    "    if include_bio:\n",
    "        bios = df.masked_bio.apply(lambda x: [text + '.' if not (text.endswith('.') or text.endswith('!') or text.endswith('?') or text.endswith(';')) else text for text in x.split('\\n')]).apply(lambda x: ' '.join(x)).apply(lambda x: re.sub('\\r', '', x)).tolist()\n",
    "    if include_tweets:\n",
    "        tweets = df.long_text.apply(lambda x: [text + '.' if not (text.endswith('.') or text.endswith('!') or text.endswith('?') or text.endswith(';')) else text for text in x.split('\\n')]).apply(lambda x: ' '.join(x)).apply(lambda x: re.sub('\\r', '', x)).tolist()\n",
    "    if include_bio and include_tweets:\n",
    "        # Join each tweet and bio by 'Bio: ' and 'Tweets: '\n",
    "        input_texts = ['Bio: ' + bio + '\\n' + 'Tweets: ' + tweet for bio, tweet in zip(bios, tweets)]\n",
    "    elif include_bio:\n",
    "        input_texts = ['Bio: ' + bio for bio in bios]\n",
    "    elif include_tweets:\n",
    "        input_texts = ['Tweets: ' + tweet for tweet in tweets]\n",
    "\n",
    "    # Read the gold labels\n",
    "    if label_name == 'is_male':\n",
    "        gold_labels = df[label_name].tolist()\n",
    "        gold_labels = ['male' if label == True else 'female' for label in gold_labels]\n",
    "    if label_name == 'age':\n",
    "        gold_labels = df[label_name].astype(int).tolist()\n",
    "    if label_name == 'age_interval':\n",
    "        # define age classes\n",
    "        age_intervals = [0, 19, 30, 40, 100]\n",
    "        age_labels = [0, 1, 2, 3]\n",
    "        # Discretize the 'age' column into four classes\n",
    "        gold_labels = pd.cut(df['age'], bins=age_intervals, labels=age_labels, right=False).astype('int').tolist()\n",
    "\n",
    "    return input_texts, gold_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff76c78e-5108-4185-ac3e-30d660846597",
   "metadata": {},
   "source": [
    "# Performance of majority-class dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4249da05-ecb9-43ae-83e9-6e0e804bf032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('male', 720), ('female', 399)]\n",
      "Ac dummy: 64.343163538874\n",
      "F1 dummy: 39.151712887438826\n"
     ]
    }
   ],
   "source": [
    "_ , gold_labels = twitter_features(test_set)\n",
    "print(Counter(gold_labels).most_common())\n",
    "dum = ~(test_set.is_male*False)\n",
    "print('Ac dummy:',accuracy_score(test_set.is_male, dum)*100)\n",
    "print('F1 dummy:',f1_score(test_set.is_male, dum, average='macro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a4fd42a1-6237-47bc-939f-800a251f5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 572), (1, 236), (2, 220), (0, 91)]\n",
      "Ac dummy: 51.117068811438784\n",
      "F1 dummy: 16.9130691898285\n",
      "AAE dummy: 14.79965061891894\n"
     ]
    }
   ],
   "source": [
    "_ , gold_labels = twitter_features(test_set, label_name='age_interval')\n",
    "print(Counter(gold_labels).most_common())\n",
    "dum = (np.array(gold_labels)*0)+3\n",
    "print('Ac dummy:',accuracy_score(gold_labels, dum)*100)\n",
    "print('F1 dummy:',f1_score(gold_labels, dum, average='macro')*100)\n",
    "\n",
    "# compute average absolute error\n",
    "mean_age_group1 = test_set[test_set.age<20].age.mean()\n",
    "mean_age_group2 = test_set[(20<=test_set.age) & (test_set.age<30)].age.mean()\n",
    "mean_age_group3 = test_set[(30<=test_set.age) & (test_set.age<40)].age.mean()\n",
    "mean_age_group4 = test_set[(40<=test_set.age) & (test_set.age<=100)].age.mean()\n",
    "class_means=[mean_age_group1, mean_age_group2, mean_age_group3, mean_age_group4]\n",
    "\n",
    "if len(class_means) > 0:\n",
    "    total_error = 0\n",
    "    for i in range(len(gold_labels)):\n",
    "        error = abs(class_means[3] - class_means[gold_labels[i]])\n",
    "        total_error += error\n",
    "    mean_error = total_error / len(gold_labels)\n",
    "    \n",
    "print('AAE dummy:', mean_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c7a31ef0-4174-42c7-b271-7e3fb9c848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_performace(p1, p2, gold_labels, class_means=[]):\n",
    "    \n",
    "    gold_labels = np.array(gold_labels)\n",
    "\n",
    "    # compute predictions\n",
    "    pred1 = p1.argmax(axis=1) \n",
    "    pred2 = p2.argmax(axis=1) \n",
    "    \n",
    "    # assign majority class as default label\n",
    "    majority_class = Counter(gold_labels).most_common()[0][0]\n",
    "    rows_with_same_p1=np.where(np.all(p1 == 1/len(np.unique(gold_labels)), axis=1))[0]\n",
    "    rows_with_same_p2=np.where(np.all(p2 == 1/len(np.unique(gold_labels)), axis=1))[0]\n",
    "    if rows_with_same_p1.size > 0:\n",
    "        print(f'{rows_with_same_p1.size} system1 predictions substituted with majority_class')\n",
    "        pred1[rows_with_same_p1] = majority_class\n",
    "    if rows_with_same_p2.size > 0:\n",
    "        print(f'{rows_with_same_p2.size} system2 predictions substituted with majority_class')\n",
    "        pred2[rows_with_same_p2] = majority_class\n",
    "    \n",
    "    print('**********')\n",
    "\n",
    "    # compute acc of models 1 and 2\n",
    "    acc1 = accuracy_score(gold_labels, pred1)\n",
    "    acc2 = accuracy_score(gold_labels, pred2)\n",
    "\n",
    "    # compute f1 of models 1 and 2\n",
    "    f11 = f1_score(gold_labels, pred1, average=None)\n",
    "    f12 = f1_score(gold_labels, pred2, average=None)\n",
    "    \n",
    "    \n",
    "    if len(class_means) > 0:\n",
    "        total_error1 = 0\n",
    "        total_error2 = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error1 = abs(class_means[pred1[i]] - class_means[gold_labels[i]])\n",
    "            error2 = abs(class_means[pred2[i]] - class_means[gold_labels[i]])\n",
    "            total_error1 += error1\n",
    "            total_error2 += error2\n",
    "        mean_error1 = total_error1 / len(gold_labels)\n",
    "        mean_error2 = total_error2 / len(gold_labels)\n",
    "\n",
    "    print('System 1')\n",
    "    print('Ac:', acc1*100)\n",
    "    print('F1:', f11.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error1)\n",
    "    print('----------')\n",
    "    print('System 2')\n",
    "    print('Ac:', acc2*100)\n",
    "    print('F1:', f12.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error2)\n",
    "    print('----------')\n",
    "\n",
    "    # compute aggregated predictions\n",
    "    p_agg = p1 + p2\n",
    "    pred_agg = p_agg.argmax(axis=1)\n",
    "    acc_agg = accuracy_score(gold_labels, pred_agg)\n",
    "    f1agg = f1_score(gold_labels, pred_agg, average=None)\n",
    "    if len(class_means) > 0:\n",
    "        total_error = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error = abs(class_means[pred_agg[i]] - class_means[gold_labels[i]])\n",
    "            total_error += error\n",
    "        mean_error = total_error / len(gold_labels)\n",
    "    print('Avg prediction system ')\n",
    "    print('Ac:', acc_agg*100)\n",
    "    print('F1:', f1agg.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error)\n",
    "    print('----------')\n",
    "    \n",
    "    p_agg = f11.mean()*p1 + f12.mean()*p2\n",
    "    pred_agg = p_agg.argmax(axis=1)\n",
    "    acc_agg = accuracy_score(gold_labels, pred_agg)\n",
    "    f1agg = f1_score(gold_labels, pred_agg, average=None)\n",
    "    if len(class_means) > 0:\n",
    "        total_error = 0\n",
    "        for i in range(len(gold_labels)):\n",
    "            error = abs(class_means[pred_agg[i]] - class_means[gold_labels[i]])\n",
    "            total_error += error\n",
    "        mean_error = total_error / len(gold_labels)\n",
    "    print('F1mean-weighted prediction system ')\n",
    "    print('Ac:', acc_agg*100)\n",
    "    print('F1:', f1agg.mean()*100)\n",
    "    if len(class_means) > 0:\n",
    "        print('MAE:', mean_error)\n",
    "    print('----------')\n",
    "\n",
    "#    p_agg = f11*p1 + f12*p2\n",
    "#    pred_agg = p_agg.argmax(axis=1)\n",
    "#    acc_agg = accuracy_score(gold_labels, pred_agg)\n",
    "#    f1agg = f1_score(gold_labels, pred_agg, average=None)\n",
    "#    if len(class_means) > 0:\n",
    "#        total_error = 0\n",
    "#        for i in len(gold_labels):\n",
    "#            error = abs(class_means[pred_agg[i]] - class_means[gold_labels[i]])\n",
    "#            total_error += error\n",
    "#        mean_error = total_error / len(gold_labels)\n",
    "#    print('F1-weighted prediction system ')\n",
    "#    print('Ac:', acc_agg*100)\n",
    "#    print('F1:', f1agg.mean()*100)\n",
    "#    if len(class_means) > 0:\n",
    "#        print('MAE:', mean_error)\n",
    "#    print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23074f96-8ad7-4707-8657-f0255a6a63d1",
   "metadata": {},
   "source": [
    "# IT gender XLM+CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e29f7823-64f2-4b67-92a3-76d9c6dd1eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 system2 predictions substituted with majority_class\n",
      "**********\n",
      "System 1\n",
      "Ac: 88.11438784629134\n",
      "F1: 86.84177720486235\n",
      "----------\n",
      "System 2\n",
      "Ac: 75.96067917783735\n",
      "F1: 70.64982424664947\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 88.82931188561216\n",
      "F1: 87.40755411713337\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 90.88471849865952\n",
      "F1: 89.88998724489797\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.column_stack((xlm_ita_gender['p_is_male'], 1 - xlm_ita_gender['p_is_male']))\n",
    "\n",
    "cv_it['p_is_male'] = cv_it.apply(lambda x: x.pred_gender_prob if bool(x.pred_is_male_label) else (1 - x.pred_gender_prob), axis=1)\n",
    "p2 = np.column_stack((cv_it['p_is_male'], 1 - cv_it['p_is_male']))\n",
    "\n",
    "gold_labels = (~test_set.is_male).astype(int)\n",
    "\n",
    "aggregate_performace(p1, p2, gold_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f8fb53-af90-4a6a-91a5-aab5ed7f6571",
   "metadata": {},
   "source": [
    "# IT age XLM+CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "52399a49-87c6-4f44-b02c-aeecd71de034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 system2 predictions substituted with majority_class\n",
      "**********\n",
      "System 1\n",
      "Ac: 66.39857015192135\n",
      "F1: 60.15930806816667\n",
      "MAE: 6.734919643762468\n",
      "----------\n",
      "System 2\n",
      "Ac: 35.210008936550494\n",
      "F1: 27.721998260576232\n",
      "MAE: 16.244698119488422\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 53.88739946380697\n",
      "F1: 45.40926898500874\n",
      "MAE: 10.076850951809869\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 64.96872207327972\n",
      "F1: 57.39832210362758\n",
      "MAE: 7.1666584028557185\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.array(xlm_ita_age[['pred_age_0_19_prob', 'pred_age_20_29_prob', 'pred_age_30_39_prob', 'pred_age_40_100_prob']])\n",
    "p2 = np.array(cv_it[['pred_age_0_19_prob', 'pred_age_20_29_prob', 'pred_age_30_39_prob', 'pred_age_40_100_prob']])\n",
    "\n",
    "_ , gold_labels = twitter_features(test_set, label_name='age_interval')\n",
    "\n",
    "aggregate_performace(p1, p2, np.array(gold_labels), class_means=[mean_age_group1, mean_age_group2, mean_age_group3, mean_age_group4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608a153-ba7f-4b0b-8470-2b6986c81208",
   "metadata": {},
   "source": [
    "# IT gender XLM+M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e55bac30-5848-4e64-bc62-3f7738098173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 system2 predictions substituted with majority_class\n",
      "**********\n",
      "System 1\n",
      "Ac: 88.11438784629134\n",
      "F1: 86.84177720486235\n",
      "----------\n",
      "System 2\n",
      "Ac: 83.10991957104558\n",
      "F1: 79.34006527449577\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 92.22520107238606\n",
      "F1: 91.22374303262394\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 91.86773905272565\n",
      "F1: 90.8202369651584\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.column_stack((xlm_ita_gender['p_is_male'], 1 - xlm_ita_gender['p_is_male']))\n",
    "p2 = np.array(m3_it[['score_male','score_female']])\n",
    "\n",
    "gold_labels = (~test_set.is_male).astype(int)\n",
    "\n",
    "aggregate_performace(p1, p2, gold_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465b81f-3693-4e1d-b578-e83af2634577",
   "metadata": {},
   "source": [
    "# IT age XLM+M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2fc0d819-d7ab-4d42-982c-259e4e29a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 system2 predictions substituted with majority_class\n",
      "**********\n",
      "System 1\n",
      "Ac: 66.39857015192135\n",
      "F1: 60.15930806816667\n",
      "MAE: 6.734919643762468\n",
      "----------\n",
      "System 2\n",
      "Ac: 53.26184092940125\n",
      "F1: 39.926094702728356\n",
      "MAE: 11.866165374882817\n",
      "----------\n",
      "Avg prediction system \n",
      "Ac: 66.66666666666666\n",
      "F1: 58.57988091767188\n",
      "MAE: 7.1738892777204315\n",
      "----------\n",
      "F1mean-weighted prediction system \n",
      "Ac: 67.20285969615728\n",
      "F1: 59.98813911025095\n",
      "MAE: 6.877285973273143\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Assuming xlm_ita_gender is a Pandas Series or NumPy array\n",
    "p1 = np.array(xlm_ita_age[['pred_age_0_19_prob', 'pred_age_20_29_prob', 'pred_age_30_39_prob', 'pred_age_40_100_prob']])\n",
    "p2 = np.array(m3_it[['score_age_cls_0','score_age_cls_1','score_age_cls_2','score_age_cls_3']])\n",
    "\n",
    "_ , gold_labels = twitter_features(test_set, label_name='age_interval')\n",
    "\n",
    "aggregate_performace(\n",
    "    p1,\n",
    "    p2,\n",
    "    gold_labels,\n",
    "    class_means=[mean_age_group1, mean_age_group2, mean_age_group3, mean_age_group4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80219e30-ae1f-4ddf-b558-5fce183b038e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASK 2022.10 (Python 3.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
