{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17eb642-2fca-4a0d-b1e8-1cabcf58ce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe7802e-10b4-4158-92fa-06a056312ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocessor():\n",
    "    \"\"\"\n",
    "    Pre-processor for tweets. Cleans mentions,\n",
    "    urls, emojis, hashtags and unix characters.\n",
    "    \"\"\"\n",
    "    def __init__(self,mention=True,url=True,unix=True,emoji=True,hashtag=False):\n",
    "        self.mention = mention\n",
    "        self.url = url\n",
    "        self.unix = unix\n",
    "        self.emoji = emoji\n",
    "        self.hashtag = hashtag\n",
    "\n",
    "    def remove_mentions(self,tweet):\n",
    "        # Remove @-mentions using regular expression\n",
    "        cleaned_tweet = re.sub(r'@\\w+', '', tweet).strip().replace('  ',' ')\n",
    "        return cleaned_tweet\n",
    "    \n",
    "    def remove_hashtags(self,tweet):\n",
    "        # Remove hashtags using regular expression\n",
    "        cleaned_tweet = re.sub(r'#\\w+', '', tweet)\n",
    "        return cleaned_tweet\n",
    "    \n",
    "    def remove_unix(self,tweet):\n",
    "        # Remove unix characters using regular expression\n",
    "        cleaned_tweet = re.sub(r'[\\n\\r\\t\\b\\f\\v]', '', tweet)\n",
    "        return cleaned_tweet\n",
    "    \n",
    "    def remove_urls(self,tweet):\n",
    "        # Remove URLs using regular expression\n",
    "        cleaned_tweet = re.sub(r'http\\S+|www\\S+', '', tweet)\n",
    "        return cleaned_tweet\n",
    "    \n",
    "    def remove_emojis(self,tweet):\n",
    "        # Remove emojis using regular expression\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        cleaned_tweet = re.sub(emoji_pattern, '', tweet)\n",
    "        return cleaned_tweet\n",
    "\n",
    "    def strip_tweet(self,tweet):\n",
    "        return tweet.strip().replace('  ',' ')\n",
    "    \n",
    "    def process_tweet(self,tweet): \n",
    "        if self.mention:\n",
    "            tweet = self.remove_mentions(tweet)\n",
    "        if self.hashtag:\n",
    "            tweet = self.remove_hashtags(tweet)\n",
    "        if self.unix:\n",
    "            tweet = self.remove_unix(tweet)\n",
    "        if self.emoji:\n",
    "            tweet = self.remove_emojis(tweet)\n",
    "        if self.url:\n",
    "            tweet = self.remove_urls(tweet)\n",
    "        tweet = self.strip_tweet(tweet)\n",
    "        return tweet\n",
    "\n",
    "    def process_list(self,tweets):\n",
    "        return [self.process_tweet(tweet) for tweet in tweets]\n",
    "    \n",
    "    def process_column(self,tweets):\n",
    "        return pd.Series(self.process_list(list(tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c3c989-0696-40c4-bad0-71eea8aba15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/g100_work/IscrC_mental'\n",
    "wdata_dir = os.path.join(work_dir, 'data')\n",
    "uc_dir = os.path.join(os.path.join(wdata_dir, 'user_classification'),'german_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae993fc6-78aa-45fe-a7eb-1739fa8b142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(uc_dir,\"german_users_with_birthyear.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f1448a-4cbd-408b-8f01-67b2bfc46142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_pickle(os.path.join(uc_dir,\"german_tweets.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867e18d6-72a7-4995-91ce-72a9c0ee597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#restrict to users for which there is a gender and birth year\n",
    "df.loc[df['male']==1,'is_male'] = 1\n",
    "df.loc[df['female']==1,'is_male'] = 0\n",
    "clean_df = df.loc[(df['is_male'].notna()) & (df['birthyear'].notna())].copy()\n",
    "#manual correction\n",
    "clean_df.loc[clean_df['user_id']==803169463197691904,'is_male']=1\n",
    "clean_df = clean_df[['user_id','is_male','birthyear','bio']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6efae9e-4e2e-48df-b497-ed45c2c60b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select last date of tweeting\n",
    "df_tweets['date']=pd.to_datetime(df_tweets.created_at)\n",
    "max_dates = df_tweets.groupby('user_id').agg({'date':max}).reset_index()\n",
    "max_dates['last_year'] = max_dates['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07cace4e-1cc4-4e30-95a0-b57251b66fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.merge(max_dates[['user_id','last_year']], on='user_id',how='inner',validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c046813-d96a-41f2-84bc-6ebb820647de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "for regex in [\"geb[\\. ].*?([12][09][0-9][0-9])\",\n",
    "              \"geboren.+?([12][09][0-9][0-9])\",\n",
    "              \"born.+?([12][09][0-9][0-9])\",\n",
    "              \"birthday.+?([12][09][0-9][0-9])\",\n",
    "              \"bday.+?([12][09][0-9][0-9])\",\n",
    "              \"([12][09][0-9][0-9]).*?geb[\\. ]\",\n",
    "              \"([12][09][0-9][0-9]).*?geboren\",\n",
    "              \"\\*.*?([12][09][0-9][0-9])\",\n",
    "              \"([1-9][0-9]) jahre alt\"]:\n",
    "    \n",
    "    d = clean_df.bio.str.extract(regex)\n",
    "    df = clean_df.assign(age = d.astype(\"Int64\"))\n",
    "    if regex != \"([1-9][0-9]) jahre alt\":\n",
    "        df.age = df.last_year-df.age\n",
    "    \n",
    "    df_all= pd.concat([df_all,df.loc[df.age.notnull()]])\n",
    "\n",
    "df_all = df_all.drop_duplicates(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9bdd4b-cdef-412b-9cc2-971b703f0276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['birthyear'] = df_all.last_year-df_all.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e08217d-0ba7-4848-aa8d-ec7e5939495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_bio(text):\n",
    "    for regex in [\"geb[\\. ].*?([12][09][0-9][0-9])\",\n",
    "              \"geboren.+?([12][09][0-9][0-9])\",\n",
    "              \"born.+?([12][09][0-9][0-9])\",\n",
    "              \"birthday.+?([12][09][0-9][0-9])\",\n",
    "              \"bday.+?([12][09][0-9][0-9])\",\n",
    "              \"([12][09][0-9][0-9]).*?geb[\\. ]\",\n",
    "              \"([12][09][0-9][0-9]).*?geboren\",\n",
    "              \"\\*.*?([12][09][0-9][0-9])\",\n",
    "              \"([1-9][0-9]) jahre alt\"]:\n",
    "        text = re.sub(regex,'',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c706e1-cdea-47e3-863a-b1f3413e3506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['masked_bio'] = df_all.bio.apply(mask_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "225d53f2-c336-4388-8719-1fd93395ab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_all.merge(df_tweets[['text','date','user_id']],on='user_id',how='inner',validate='1:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "86567b8b-6a02-4397-b8ae-7f58b7efe243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RT'] = df['text'].str.startswith('RT @')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26affe41-6cae-46d9-9e1d-dcc2f073ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['RT']==False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e59c90da-955e-4f39-a0e7-9ff56470cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[-(df['age']>100) & (df['age']>=10)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c6112c45-9295-4c35-951c-74674d820fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove mentions, urls and empty tweets\n",
    "pp = preprocessor(mention=True,url=True,unix=False,emoji=False,hashtag=False)\n",
    "df['text']= df['text'].apply(pp.process_tweet)\n",
    "df = df[df['text']!=''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3c630f3-896d-4493-a8d7-2f84dd1a3121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.11016664/ipykernel_404688/2838337157.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['rank'] = df_text.groupby('user_id')['date'].rank(method='first', ascending=False)\n"
     ]
    }
   ],
   "source": [
    "def transform_df(df, N=100):\n",
    "    # df bio\n",
    "    df_bio = df[['user_id', 'masked_bio', 'age', 'is_male']].fillna('').drop_duplicates()\n",
    "    \n",
    "    # process tweets\n",
    "    df_text = df[['user_id', 'text', 'date', 'age', 'is_male']]\n",
    "    \n",
    "    # keep the N most recent text_masked\n",
    "    df_text['rank'] = df_text.groupby('user_id')['date'].rank(method='first', ascending=False)\n",
    "    \n",
    "    # Filter out entries with rank greater than N\n",
    "    df_text = df_text[df_text['rank'] <= N]\n",
    "    \n",
    "    df_text_grouped = df_text.groupby('user_id')['text'].agg(lambda x: '\\n'.join(x)).reset_index()\n",
    "    df_text_grouped = df_text_grouped.rename(columns={'text': 'long_text'})\n",
    "    \n",
    "    # Merge df_bio with df_text_grouped\n",
    "    result_df = pd.merge(df_bio, df_text_grouped, on='user_id', how='inner')\n",
    "\n",
    "    return result_df\n",
    "\n",
    "dft = transform_df(df, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b12a894e-5f1d-4a2a-92b0-ea6f88c2361a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.to_pickle(os.path.join(uc_dir,'data_for_models_german_data.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba6f1f9e-b2c8-4943-a6f5-4e3575a8fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft.to_pickle('/g100/home/userexternal/pbose000/twitter_user_classification/data/user_classification/data_for_models_german_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c3d05-7d18-4131-a855-74b6f29a95ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "mentalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
