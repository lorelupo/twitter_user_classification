{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57faf093-c948-428c-b7a1-0b5b67b0cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b220872-5afb-410d-9633-209d89b141b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/g100_work/IscrC_mental'\n",
    "wdata_dir = os.path.join(work_dir, 'data')\n",
    "uc_dir = os.path.join(wdata_dir, 'user_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d7ebb0-0b6e-4f5b-89a0-1ab7c44a9836",
   "metadata": {},
   "source": [
    "### Maskig age/birthdate in bio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ae0d23-3745-48a1-8f28-01ee34ea4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_CHAR = [\n",
    "    'novantanove',\n",
    "    'novantotto',\n",
    "    'novantasette',\n",
    "    'novantasei',\n",
    "    'novantacinque',\n",
    "    'novantaquattro',\n",
    "    'novantatre',\n",
    "    'novantadue',\n",
    "    'novantuno',\n",
    "    'novanta',\n",
    "    'ottantanove',\n",
    "    'ottantotto',\n",
    "    'ottantasette',\n",
    "    'ottantasei',\n",
    "    'ottantacinque',\n",
    "    'ottantaquattro',\n",
    "    'ottantatre',\n",
    "    'ottantadue',\n",
    "    'ottantuno',\n",
    "    'ottanta',\n",
    "    'settantanove',\n",
    "    'settantotto',\n",
    "    'settantasette',\n",
    "    'settantasei',\n",
    "    'settantacinque',\n",
    "    'settantaquattro',\n",
    "    'settantatre',\n",
    "    'settantadue',\n",
    "    'settantuno',\n",
    "    'settanta',\n",
    "    'sessantanove',\n",
    "    'sessantotto',\n",
    "    'sessantasette',\n",
    "    'sessantasei',\n",
    "    'sessantacinque',\n",
    "    'sessantaquattro',\n",
    "    'sessantatre',\n",
    "    'sessantadue',\n",
    "    'sessantuno',\n",
    "    'sessanta',\n",
    "    'cinquantanove',\n",
    "    'cinquantotto',\n",
    "    'cinquantasette',\n",
    "    'cinquantasei',\n",
    "    'cinquantacinque',\n",
    "    'cinquantaquattro',\n",
    "    'cinquantatre',\n",
    "    'cinquantadue',\n",
    "    'cinquantuno',\n",
    "    'cinquanta',\n",
    "    'quarantanove',\n",
    "    'quarantotto',\n",
    "    'quarantasette',\n",
    "    'quarantasei',\n",
    "    'quarantacinque',\n",
    "    'quarantaquattro',\n",
    "    'quarantatre',\n",
    "    'quarantadue',\n",
    "    'quarantuno',\n",
    "    'quaranta',\n",
    "    'trentanove',\n",
    "    'trentotto',\n",
    "    'trentasette',\n",
    "    'trentasei',\n",
    "    'trentacinque',\n",
    "    'trentaquattro',\n",
    "    'trentatre',\n",
    "    'trentadue',\n",
    "    'trentuno',\n",
    "    'trenta',\n",
    "    'ventinove',\n",
    "    'ventotto',\n",
    "    'ventisette',\n",
    "    'ventisei',\n",
    "    'venticinque',\n",
    "    'ventiquattro',\n",
    "    'ventitre',\n",
    "    'ventidue',\n",
    "    'ventuno',\n",
    "    'venti',\n",
    "    'diciannove',\n",
    "    'diciotto',\n",
    "    'diciassette',\n",
    "    'sedici',\n",
    "    'quindici',\n",
    "    'quattordici',\n",
    "    'tredici'\n",
    " ]\n",
    "\n",
    "# remove last letter of each years_in_words entry, in order to match both\n",
    "# the noun (\"ventiquattro\") and the adjective (\"ventiquattrenne\")\n",
    "AGE_CHAR_SUFFIX_LONG = [year[:-1] for year in AGE_CHAR]\n",
    "\n",
    "# keep only the shortest form as a first filter\n",
    "AGE_CHAR_SUFFIX_SHORT = [\n",
    "    \"tredic\",\n",
    "    \"quattordic\",\n",
    "    \"quindic\",\n",
    "    \"sedic\",\n",
    "    \"diciasset\",\n",
    "    \"diciott\",\n",
    "    \"diciannov\",\n",
    "    \"vent\",\n",
    "    \"trent\",\n",
    "    \"quarant\",\n",
    "    \"cinquant\",\n",
    "    \"sessant\",\n",
    "    \"settant\",\n",
    "    \"ottant\",\n",
    "    \"novant\",\n",
    "]\n",
    "\n",
    "AGE_DIGIT = list(range(99,12,-1))\n",
    "\n",
    "# List of regex patterns for matching Twitter posts mentioning the age of the user\n",
    "# The patterns are built using the age expressed in digits (e.g. \"22\" for 22)\n",
    "AGE_DIGIT_PATTERNS = [\n",
    "    # Matches phrases like \"ho compiuto 22 anni\" (I just turned 22)\n",
    "    # but not \"quando ho compiuto 22 anni\" (when I turned 22)\n",
    "    # nor \"ho compiuto 22 anni di/de\" (I have 22 years of)\n",
    "    r\"(?<!quando\\s)(?<!quando)ho\\s*compiuto\\s*(\\d{2})\\s*anni(?! su)(?! più)(?! da)(?! de)(?! di)(?!de)(?!di)(?!su)(?!più)(?!da)(?! in più)(?! in meno)\",\n",
    "    r\"\\bcompio\\s*(\\d{2})\\s*anni(?! su)(?! più)(?! da)(?! de)(?! di)(?!de)(?!di)(?!su)(?!più)(?!da)(?! in più)(?! in meno)\",\n",
    "    # Matches phrases like \"ho 22 anni\" (I am 22 years old)\n",
    "    # but not \"da quando/non ho 22 anni\" (since I am / I am not 22 years old)\n",
    "    # nor \"ho 22 anni di/de\" (I have 22 years of)\n",
    "    # nor \"se ho 22 anni\" (if I am 22 years old)\n",
    "    r\"(?<!quando\\s)(?<!quando)(?<!non\\s)(?<!non)(?<!se\\s)(?<!se)ho\\s*(\\d{2})\\s*anni(?! su)(?! più)(?! da)(?! de)(?! di)(?!de)(?!di)(?!su)(?!più)(?!da)(?! in più)(?! in meno)\",\n",
    "    # Matches phrases like \"faccio 22 anni\" (I am turning 22 years old)\n",
    "    # but not \"faccio 22 anni di/de\" (I have 22 years of)\n",
    "    r\"\\bfaccio\\s*(\\d{2})\\s*anni(?! che)(?! su)(?! più)(?! da)(?! de)(?! di)(?!de)(?!di)(?!su)(?!più)(?!da)(?! in più)(?! in meno)(?!che)\",\n",
    "    # Matches phrases like \"spengo 22 candeline\" (I am blowing 22 candles)\n",
    "    r\"\\bspengo\\s*(\\d{2})\\s*candeline\",\n",
    "    # Matches phrases like \"il mio 22^ compleanno\" (my 22nd birthday)\n",
    "    r\"il\\s*mio\\s*(\\d{2})\\^\\s*comple(?:anno)?\",\n",
    "    # Matches phrases like \"sono un 22enne\" (I am a 22-year-old...)\n",
    "    r\"\\bsono\\s*una?\\s*(\\d{2})\\s*enne\",\n",
    "    # Matches phrases like \"i miei 22 anni\" (my 22 years)\n",
    "    # r\"\\bmiei\\s*(\\d{2})\\s*anni\",\n",
    "]\n",
    "\n",
    "YEAR_OF_BIRTH_PATTERNS = [\n",
    "    # Matches sentences like \"sono nato nel 1993/93/'93\" (I was born in 1993)\n",
    "    r\"\\bsono\\s*nato\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bsono\\s*nata\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono del 1993/93/'93\" (I am from 1993)\n",
    "    # r\"sono\\s*del\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono un 1993/93/'93\" (I am a 1993)\n",
    "    # r\"sono\\s*una?\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono della generazione 1993/93/'93\" (I am generation 1993)\n",
    "    r\"sono\\s*della\\s*generazione\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono classe 1993/93/'93\" (I am class 1993)\n",
    "    r\"sono\\s*classe\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"sono\\s*una?\\s*classe\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "]\n",
    "\n",
    "YEAR_OF_BIRTH_PATTERNS_BIO = [\n",
    "    # Matches sentences like \"sono nato nel 1993/93/'93\" (I was born in 1993)\n",
    "    r\"\\bsono\\s*nato\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bsono\\s*nata\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bnato\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bnata\\s*nel\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bborn\\s*in\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono del 1993/93/'93\" (I am from 1993)\n",
    "    r\"sono\\s*del\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono un 1993/93/'93\" (I am a 1993)\n",
    "    r\"sono\\s*una?\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono della generazione 1993/93/'93\" (I am generation 1993)\n",
    "    r\"sono\\s*della\\s*generazione\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bgenerazione\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    # Matches sentences like \"sono classe 1993/93/'93\" (I am class 1993)\n",
    "    r\"sono\\s*classe\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"sono\\s*una?\\s*classe\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "    r\"\\bclasse\\s*(20[0-1][0-9]|19[0-9][0-9]|\\D\\d{2}\\s|\\D\\d{2}$)\",\n",
    "]\n",
    "\n",
    "def return_full_age_char_pattern(age_char):\n",
    "    \"\"\"\n",
    "    Returns a list of regex patterns for matching Twitter posts mentioning the age of the user.\n",
    "    The patterns are built using the age_char parameter, which is a string containing the\n",
    "    Italian word for the age of the user (e.g. \"ventidue\" for 22).\n",
    "    \"\"\"\n",
    "    age_char_patterns = [\n",
    "            # Matches phrases like \"ho compiuto ventidue anni\" (I just turned twenty-two)\n",
    "            # but not \"quando ho compiuto ventidue anni\" (when I turned twenty-two)\n",
    "            # nor \"ho compiuto ventidue anni di/de\" (I have twenty-two years of)\n",
    "            r\"(?<!quando\\s)(?<!quando)ho\\s*compiuto\\s*({}).*\\s*anni(?! de)(?!de)(?! di)(?!di)(?! in più)(?! in meno)\".format(age_char),\n",
    "            r\"\\bcompio\\s*({}).*\\s*anni(?! de)(?! di)(?!de)(?!di)\".format(age_char),\n",
    "            # Matches phrases like \"ho ventidue anni\" (I am twenty-two years old),\n",
    "            # but not \"a quando/non ho ventidue anni\" (since I am / I am not twenty-two years old)\n",
    "            # nor \"ho ventidue anni di/de\" (I have twenty-two years of)\n",
    "            # nor \"se ho ventidue anni\" (if I am twenty-two years old)\n",
    "            r\"(?<!quando\\s)(?<!quando)(?<!non\\s)(?<!non)(?<!se\\s)(?<!se)ho\\s*({}).*\\s*anni(?! de)(?! di)(?!de)(?!di)(?! in più)(?! in meno)\".format(age_char),\n",
    "            # Matches phrases like \"faccio ventidue anni\" (I am turning twenty-two years old)\n",
    "            r\"\\bfaccio\\s*({}).*\\s*anni(?! de)(?! di)(?!de)(?!di)\".format(age_char),\n",
    "            # Matches phrases like \"spengo ventidue candeline\" (I am blowing twenty-two candles)\n",
    "            r\"\\bspengo\\s*({})\\s*candeline\".format(age_char),\n",
    "            # Matches phrases like \"mio ventiduesimo comple/compleanno\" (my twenty-second birthday)\n",
    "            r\"il\\s*mio\\s*{}e?simo\\s*comple(?:anno)?\".format(age_char),\n",
    "            # Matches phrases like \"sono un ventiduenne\" (I am twenty-two-years-old...)\n",
    "            r\"\\bsono\\s*una?\\s*({})\\s*e?nne\".format(age_char),\n",
    "            # Matches phrases like \"i miei ventidue anni\" (my twenty-two years)\n",
    "            # r\"\\bmiei\\s*({}).*\\s*anni\".format(age_char),\n",
    "        ]\n",
    "    return age_char_patterns\n",
    "\n",
    "def remove_age_pattern(text):\n",
    "\n",
    "    # search for year of birth patterns\n",
    "    for pattern in YEAR_OF_BIRTH_PATTERNS:\n",
    "        pattern = \"(\" + pattern + \")\"\n",
    "        newtext = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "        if newtext != text:\n",
    "            return newtext\n",
    "\n",
    "    # search for year of birth patterns\n",
    "    for pattern in AGE_DIGIT_PATTERNS:\n",
    "        pattern = \"(\" + pattern + \")\"\n",
    "        newtext = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "        if newtext != text:\n",
    "            return newtext\n",
    "\n",
    "    # check if the text contains an age expressed in characters\n",
    "    if re.search(r\"{}\".format(\"|\".join(AGE_CHAR_SUFFIX_SHORT)), text, flags=re.IGNORECASE):\n",
    "        # check what age is expressed in the tweet and retrieve its index\n",
    "        matching_age_char = re.findall(r\"{}\".format(\"|\".join(AGE_CHAR_SUFFIX_LONG)), text, flags=re.IGNORECASE)[0].lower()\n",
    "        matching_age_char_index = AGE_CHAR_SUFFIX_LONG.index(matching_age_char)\n",
    "        # check if the age is not in a quoted text\n",
    "        if not re.search(r\"\\\".*{}.*\\\"\".format(matching_age_char), text, flags=re.IGNORECASE) \\\n",
    "            and not re.search(r\"\\“.*{}.*\\”\".format(matching_age_char), text, flags=re.IGNORECASE) \\\n",
    "            and not re.search(r\"\\«.*{}.*\\»\".format(matching_age_char), text, flags=re.IGNORECASE):\n",
    "            # check if also the full form of the age is present in the text\n",
    "            if re.search(r\"{}\".format(AGE_CHAR[matching_age_char_index]), text, flags=re.IGNORECASE):\n",
    "                patterns = return_full_age_char_pattern(AGE_CHAR[matching_age_char_index])\n",
    "            else:\n",
    "                patterns = return_full_age_char_pattern(AGE_CHAR_SUFFIX_LONG[matching_age_char_index])\n",
    "            # search for age statements and retrieve age\n",
    "            for pattern in patterns:\n",
    "                pattern = \"(\" + pattern + \")\"\n",
    "                newtext = re.sub(pattern, \"\", text, flags=re.IGNORECASE)\n",
    "                if newtext != text:\n",
    "                    return newtext\n",
    "\n",
    "    # search for year of birth patterns\n",
    "    for pattern in YEAR_OF_BIRTH_PATTERNS_BIO:\n",
    "        pattern = \"(\" + pattern + \")\"\n",
    "        newtext = re.sub(pattern, \"\", text , flags=re.IGNORECASE)\n",
    "        if newtext != text:\n",
    "            return newtext\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a32e9c3-9ba0-4889-954e-fda9cbc326c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read users data\n",
    "path_train  = os.path.join(uc_dir, 'user_age_gender_location_train_set.pkl')\n",
    "path_test  = os.path.join(uc_dir, 'user_age_gender_location_test_set.pkl')\n",
    "df_agl_train = pd.read_pickle(path_train)\n",
    "df_agl_test = pd.read_pickle(path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4f9f0a4-af98-4725-b0a8-ab6ac2548678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for entries where 'regex_type' starts with 'bio'\n",
    "df_agl_train['bio_mask'] = df_agl_train['regex_type'].str.startswith('bio').astype(int)\n",
    "df_agl_test['bio_mask'] = df_agl_test['regex_type'].str.startswith('bio').astype(int)\n",
    "\n",
    "# Sort by user_id and the bio_mask to ensure bio entries come first\n",
    "df_agl_train = df_agl_train.sort_values(by=['user_id', 'bio_mask'], ascending=[True, False])\n",
    "df_agl_test = df_agl_test.sort_values(by=['user_id', 'bio_mask'], ascending=[True, False])\n",
    "\n",
    "# Drop duplicates based on user_id, keeping only the first occurrence\n",
    "df_agl_train = df_agl_train.drop_duplicates(subset='user_id', keep='first')\n",
    "df_agl_test = df_agl_test.drop_duplicates(subset='user_id', keep='first')\n",
    "\n",
    "# Drop the bio_mask column, as it's no longer needed\n",
    "df_agl_train.drop('bio_mask', axis=1, inplace=True)\n",
    "df_agl_test.drop('bio_mask', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcdca8d5-c1e4-4b60-8d7a-34c1665e5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df_agl_train, df_agl_test):\n",
    "    \n",
    "    df['masked_bio'] = df['bio'].fillna('').apply(lambda x: remove_age_pattern(x) )\n",
    "    df['masked_tweet'] = df['tweet'].fillna('').apply(lambda x: remove_age_pattern(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2faf8bb3-1e79-44a7-bc42-aeac5ba4f271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df_agl in (df_agl_train, df_agl_test):\n",
    "#     # Iterate over each row and apply the mask_bio function\n",
    "#     df_agl['masked_bio'] = df_agl['bio']\n",
    "#     df_agl['masked_tweet'] = df_agl['tweet']\n",
    "\n",
    "#     for idx, row in df_agl.iterrows():\n",
    "#         if row['regex_type'].startswith('bio'):\n",
    "#             df_agl.at[idx, 'masked_bio'] = mask_bio(row['bio'], row['regex_type'], row['age_raw'])\n",
    "\n",
    "#         else: \n",
    "#             df_agl.at[idx, 'masked_tweet'] = mask_bio(row['tweet'], row['regex_type'], row['age_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b284721-06fd-44fa-9698-50066756c6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19200, 40)\n",
      "(1120, 40)\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "path_train  = os.path.join(uc_dir, 'user_age_gender_location_train_set_masked.pkl')\n",
    "path_test  = os.path.join(uc_dir, 'user_age_gender_location_test_set_masked.pkl')\n",
    "df_agl_train.to_pickle(path_train)\n",
    "df_agl_test.to_pickle(path_test)\n",
    "\n",
    "print(df_agl_train.shape)\n",
    "print(df_agl_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd4290-46d0-44b0-8e26-abe19d234b09",
   "metadata": {},
   "source": [
    "### Create Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e9953a-8df9-47dd-969b-ca5db560b966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29304512, 8)\n"
     ]
    }
   ],
   "source": [
    "# load tweets\n",
    "path = os.path.join(uc_dir, 'tweets_by_user_id_clean.pkl')\n",
    "df_twt = pd.read_pickle(path)\n",
    "\n",
    "print(df_twt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e008f7-193f-41e9-ad91-e960c6fe7bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22315330, 5)\n"
     ]
    }
   ],
   "source": [
    "# create date column\n",
    "df_twt['date'] = pd.to_datetime(df_twt['created_at'].str.slice(0,10))\n",
    "\n",
    "# last_tweet year for each user\n",
    "df_last = df_twt[['user_id', 'date']].sort_values(by=['user_id', 'date'], ascending=False)\n",
    "df_last = df_last.drop_duplicates(subset='user_id', keep='first')\n",
    "df_last.columns = ['user_id', 'last_tweet']\n",
    "df_last['last_tweet'] = df_last['last_tweet'].dt.year\n",
    "\n",
    "# discard retweets\n",
    "df_twt = df_twt[df_twt['RT']==False]\n",
    "# keep only it tweets:\n",
    "# df_twt = df_twt[df_twt['language']=='it']\n",
    "\n",
    "# keep selected columns\n",
    "df_twt = df_twt[[ 'user_id', 'text', 'tweet_id', 'date', 'language']]\n",
    "\n",
    "print(df_twt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6fc9612-b7c5-4efe-b284-ae9e5f4dc0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19200, 40)\n",
      "(1120, 40)\n",
      "(19200, 41)\n",
      "(1120, 41)\n"
     ]
    }
   ],
   "source": [
    "# load users masked data\n",
    "path_train  = os.path.join(uc_dir, 'user_age_gender_location_train_set_masked.pkl')\n",
    "path_test  = os.path.join(uc_dir, 'user_age_gender_location_test_set_masked.pkl')\n",
    "\n",
    "df_um_train = pd.read_pickle(path_train)\n",
    "df_um_test = pd.read_pickle(path_test)\n",
    "\n",
    "print(df_um_train.shape)\n",
    "print(df_um_test.shape)\n",
    "\n",
    "# merge with last tweet data\n",
    "df_um_train = df_um_train.merge(df_last, on='user_id', how='left')\n",
    "df_um_test = df_um_test.merge(df_last, on='user_id', how='left')\n",
    "\n",
    "print(df_um_train.shape)\n",
    "print(df_um_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5147c991-1fde-477f-8858-80fa2ada25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_um in (df_um_train,df_um_test):\n",
    "    # specify age based on the date of the last tweet\n",
    "    df_um['age'] = 0\n",
    "\n",
    "    for idx, row in df_um.iterrows():\n",
    "        if row['regex_type'].startswith('bio'):\n",
    "            if row['regex_type'].endswith('birth_year'): \n",
    "                df_um.at[idx, 'age'] = row['last_tweet'] - int(row['age_raw'])\n",
    "            else: \n",
    "                df_um.at[idx, 'age'] =  int(row['age_raw']) # the raw age if mentioned in the bio\n",
    "                \n",
    "        # for tweets       \n",
    "        else:\n",
    "            df_um.at[idx, 'age'] = row['age_when_tweeted'] + (row['last_tweet']-row['year_tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88af8cfd-c97a-41ff-a7c6-0cccf4bd2d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_raw</th>\n",
       "      <th>age</th>\n",
       "      <th>last_tweet</th>\n",
       "      <th>year_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>2022</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>2023</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "      <td>2022</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>2023</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19199</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17622 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_raw  age  last_tweet  year_tweet\n",
       "0           52   55        2022      2019.0\n",
       "1           45   49        2023      2019.0\n",
       "2           27   28        2022      2021.0\n",
       "3           32   39        2022      2015.0\n",
       "4           40   42        2023      2021.0\n",
       "...        ...  ...         ...         ...\n",
       "19194       41   41        2023      2023.0\n",
       "19195       22   22        2023      2023.0\n",
       "19197       40   40        2023      2023.0\n",
       "19198       63   63        2023      2023.0\n",
       "19199       47   47        2023      2023.0\n",
       "\n",
       "[17622 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_um_train[~ df_um_train['regex_type'].str.startswith('bio')][['age_raw', 'age', 'last_tweet', 'year_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec6a764-0134-4f6f-bd11-a1467e9d04aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19200, 41)\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_um_train.shape)\n",
    "print(df_um_train['age'].isna().sum())\n",
    "print(df_um_test['age'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88ff7e46-f628-4de7-8905-13c3b9582bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, N=1000):\n",
    "    # df bio\n",
    "    df_bio = df[df['masked_tweet'].notna()]\n",
    "    df_bio = df_bio[['user_id', 'masked_bio']].fillna('').drop_duplicates()\n",
    "    \n",
    "    # process tweets\n",
    "    df_text = df[['user_id', 'text', 'masked_tweet', 'has_mask', 'date']]\n",
    "    \n",
    "    #  if has mask, use the masked_version\n",
    "    df_text['text_masked'] = df_text.apply(lambda x: x['text'] if x['has_mask'] == 0 else x['masked_tweet'], axis=1)\n",
    "    \n",
    "    # keen the N most recent text_masked\n",
    "    df_text['rank'] = df_text.groupby('user_id')['date'].rank(method='first', ascending=False)\n",
    "    \n",
    "    # Filter out entries with rank greater than N\n",
    "    df_text = df_text[df_text['rank'] <= N]\n",
    "    \n",
    "    df_text_grouped = df_text.groupby('user_id')['text_masked'].agg(lambda x: '\\n'.join(x)).reset_index()\n",
    "    df_text_grouped = df_text_grouped.rename(columns={'text_masked': 'long_text'})\n",
    "    \n",
    "    # Merge df_bio with df_text_grouped\n",
    "    result_df = pd.merge(df_bio, df_text_grouped, on='user_id', how='right').fillna('')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ddadc2b-0b86-47a4-91f1-53a80c3cfb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (20784479, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10981823/ipykernel_8339/1476230120.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['text_masked'] = df_text.apply(lambda x: x['text'] if x['has_mask'] == 0 else x['masked_tweet'], axis=1)\n",
      "/scratch_local/slurm_job.10981823/ipykernel_8339/1476230120.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['rank'] = df_text.groupby('user_id')['date'].rank(method='first', ascending=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1266864, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch_local/slurm_job.10981823/ipykernel_8339/1476230120.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['text_masked'] = df_text.apply(lambda x: x['text'] if x['has_mask'] == 0 else x['masked_tweet'], axis=1)\n",
      "/scratch_local/slurm_job.10981823/ipykernel_8339/1476230120.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text['rank'] = df_text.groupby('user_id')['date'].rank(method='first', ascending=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# merge bio and tweets\n",
    "\n",
    "# merge selected columns only\n",
    "columns= ['user_id', 'username' ,'full_name', 'is_male', 'age' , 'masked_bio']\n",
    "\n",
    "\n",
    "# for train #########################################################\n",
    "df_um = df_um_train\n",
    "\n",
    "# merge with tweets\n",
    "df_ut = df_um[columns].merge(df_twt, on='user_id', how='inner')\n",
    "\n",
    "# merge with masked tweets\n",
    "df_ut = df_ut.merge(df_um[df_um['masked_tweet'].notna()][['tweet_id', 'masked_tweet']], \n",
    "                    on='tweet_id', how='left')\n",
    "\n",
    "# flag tweets that are masked\n",
    "df_ut['has_mask'] = df_ut['masked_tweet'].notna().astype(int)\n",
    "\n",
    "# sort by date\n",
    "df_ut = df_ut.sort_values(by=['user_id', 'date'], ascending=False).reset_index(drop=True)\n",
    "print('Train shape:', df_ut.shape)\n",
    "\n",
    "\n",
    "# transform tweets into a long text\n",
    "df_utt = transform_df(df_ut)\n",
    "\n",
    "df_uttr = df_um[['user_id', 'is_male', 'age']].merge(df_utt, on='user_id')\n",
    "\n",
    "# save\n",
    "path  = os.path.join(uc_dir, 'data_for_models_train.pkl')\n",
    "df_uttr.to_pickle(path)\n",
    "\n",
    "\n",
    "\n",
    "# for test #########################################################\n",
    "df_um = df_um_test\n",
    "\n",
    "# merge with tweets\n",
    "df_ut = df_um[columns].merge(df_twt, on='user_id', how='inner')\n",
    "\n",
    "# merge with masked tweets\n",
    "df_ut = df_ut.merge(df_um[df_um['masked_tweet'].notna()][['tweet_id', 'masked_tweet']], \n",
    "                    on='tweet_id', how='left')\n",
    "\n",
    "# flag tweets that are masked\n",
    "df_ut['has_mask'] = df_ut['masked_tweet'].notna().astype(int)\n",
    "\n",
    "# sort by date\n",
    "df_ut = df_ut.sort_values(by=['user_id', 'date'], ascending=False).reset_index(drop=True)\n",
    "print('Train shape:', df_ut.shape)\n",
    "\n",
    "# transform tweets into a long text\n",
    "df_utt = transform_df(df_ut)\n",
    "\n",
    "df_utts = df_um[['user_id', 'is_male', 'age']].merge(df_utt, on='user_id')\n",
    "\n",
    "# save\n",
    "path  = os.path.join(uc_dir, 'data_for_models_test.pkl')\n",
    "df_utts.to_pickle(path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DASK 2022.10 (Python 3.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
