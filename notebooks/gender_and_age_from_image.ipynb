{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79231f3e-809d-49d2-a7ee-47735096c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16f40cf3-4567-4e0a-92ce-341fe3e41791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model paths and labels\n",
    "model_dir = '/g100_scratch/userexternal/pbose000/mentalism/img_prediction/cv_models'\n",
    "GENDER_MODEL = os.path.join(model_dir, 'deploy_gender.prototxt')\n",
    "GENDER_PROTO = os.path.join(model_dir,'gender_net.caffemodel')\n",
    "AGE_MODEL = os.path.join(model_dir, 'deploy_age.prototxt')\n",
    "AGE_PROTO = os.path.join(model_dir,'age_net.caffemodel')\n",
    "FACE_PROTO = os.path.join(model_dir,'deploy.prototxt')\n",
    "FACE_MODEL =  os.path.join(model_dir,'res10_300x300_ssd_iter_140000_fp16.caffemodel')\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_INTERVALS = ['(0, 19)', '(20,29)', '(30, 40)', '(40, 100)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa898ecb-11fb-4f6d-98dd-31296005be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image paths and load all image paths\n",
    "img_dir = '/g100_work/IscrC_mental/data/user_classification/images/'\n",
    "imgs = {}\n",
    "imgs['train'] = glob.glob(os.path.join(img_dir,'train')+'/*')\n",
    "imgs['test'] = glob.glob(os.path.join(img_dir,'test')+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d43381-5beb-4cb8-a04c-b2db42471040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load face Caffe model\n",
    "face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n",
    "# Load gender prediction model\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_MODEL, GENDER_PROTO)\n",
    "age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ee58e7-f3b6-45d2-b5e0-34c34fa0b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize frame size\n",
    "frame_width = 1280\n",
    "frame_height = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1c7914-1ca9-4aa0-8b2c-44234b7ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(frame, confidence_threshold=0.5):\n",
    "    # convert the frame into a blob to be ready for NN input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
    "    # set the image as input to the NN\n",
    "    face_net.setInput(blob)\n",
    "    # perform inference and get predictions\n",
    "    output = np.squeeze(face_net.forward())\n",
    "    # initialize the result list\n",
    "    faces = []\n",
    "    # Loop over the faces detected\n",
    "    for i in range(output.shape[0]):\n",
    "        confidence = output[i, 2]\n",
    "        if confidence > confidence_threshold:\n",
    "            box = output[i, 3:7] * \\\n",
    "                np.array([frame.shape[1], frame.shape[0],\n",
    "                         frame.shape[1], frame.shape[0]])\n",
    "            # convert to integers\n",
    "            start_x, start_y, end_x, end_y = box.astype(int)\n",
    "            # widen the box a little\n",
    "            start_x, start_y, end_x, end_y = start_x - \\\n",
    "                10, start_y - 10, end_x + 10, end_y + 10\n",
    "            start_x = 0 if start_x < 0 else start_x\n",
    "            start_y = 0 if start_y < 0 else start_y\n",
    "            end_x = 0 if end_x < 0 else end_x\n",
    "            end_y = 0 if end_y < 0 else end_y\n",
    "            # append to our list\n",
    "            faces.append((start_x, start_y, end_x, end_y))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391e2bfc-cd9f-473e-9600-5655ade301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    # resize the image\n",
    "    return cv2.resize(image, dim, interpolation = inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "efdddcae-7447-4617-8cc5-ea804f88f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(input_path: str):\n",
    "    \"\"\"Predict the gender of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # resize the image, uncomment if you want to resize the image\n",
    "    # img = cv2.resize(img, (frame_width, frame_height))\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    # predict the faces\n",
    "    faces = get_faces(frame)\n",
    "    # Loop over the faces detected\n",
    "    # for idx, face in enumerate(faces):\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        # scale factor = After performing mean substraction we can optionally scale the image by some factor. (if 1 -> no scaling)\n",
    "        # size = The spatial size that the CNN expects. Options are = (224*224, 227*227 or 299*299)\n",
    "        # mean = mean substraction values to be substracted from every channel of the image.\n",
    "        # swapRB=OpenCV assumes images in BGR whereas the mean is supplied in RGB. To resolve this we set swapRB to True.\n",
    "        blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n",
    "            227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n",
    "        # Predict Gender\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        i = gender_preds[0].argmax()\n",
    "        gender = GENDER_LIST[i]\n",
    "        gender_confidence_score = gender_preds[0][i]\n",
    "        \n",
    "        # Label processed image\n",
    "        results.append([gender, gender_confidence_score])\n",
    "    \n",
    "    if len(results)==0:\n",
    "        results = ['Male',0.5]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_gender(results)\n",
    "    else:\n",
    "        results = results[0]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_gender(results):\n",
    "    p = 0\n",
    "    for i in results:\n",
    "        if i[0]=='Male':\n",
    "            p += i[1]\n",
    "        else:\n",
    "            p += 1 - i[1]\n",
    "    p = p/len(results)\n",
    "    if p>0.5:\n",
    "        return ['Male',p]\n",
    "    else:\n",
    "        return ['Female',1-p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "db34b71f-19c1-412d-883b-e60a2c375172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age(input_path: str):\n",
    "    \"\"\"Predict the age of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    faces = get_faces(frame)\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image=face_img, scalefactor=1.0, size=(227, 227), \n",
    "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "        )\n",
    "        # Predict Age\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_preds = convert_age_interval(age_preds[0])\n",
    "        #t = age_preds.argmax()\n",
    "        #age = AGE_INTERVALS[t]\n",
    "        #age_confidence_score = age_preds[t]\n",
    "        results.append(age_preds)\n",
    "    if len(results)==0:\n",
    "        results = [AGE_INTERVALS[3],0.25]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_age(results)\n",
    "    else:\n",
    "        t = results[0].argmax()\n",
    "        age = AGE_INTERVALS[t]\n",
    "        age_confidence_score = results[0][t]\n",
    "        results = [age,age_confidence_score]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_age(results):\n",
    "    p = np.zeros(len(results[0]))\n",
    "    for i in results:\n",
    "        p += i\n",
    "    p = p/len(results)\n",
    "    t = p.argmax()\n",
    "    age = AGE_INTERVALS[t]\n",
    "    age_confidence_score = p[t]\n",
    "    return [age,age_confidence_score]\n",
    "\n",
    "\n",
    "def convert_age_interval(age_preds):\n",
    "    ages=[age_preds[0]+age_preds[1]+age_preds[2]+age_preds[3],age_preds[4],age_preds[5],age_preds[6]+age_preds[7]]\n",
    "    return np.array(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "263105df-c6e7-4060-97a5-ed122fe4c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age_all_classes(input_path: str):\n",
    "    \"\"\"Predict the age of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    faces = get_faces(frame)\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image=face_img, scalefactor=1.0, size=(227, 227), \n",
    "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "        )\n",
    "        # Predict Age\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_preds = convert_age_interval(age_preds[0])\n",
    "        #t = age_preds.argmax()\n",
    "        #age = AGE_INTERVALS[t]\n",
    "        #age_confidence_score = age_preds[t]\n",
    "        results.append(age_preds)\n",
    "    if len(results)==0:\n",
    "        results = [0.25,0.25,0.25,0.25]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_age_classes(results)\n",
    "    else:\n",
    "        results = results[0]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_age_classes(results):\n",
    "    p = np.zeros(len(results[0]))\n",
    "    for i in results:\n",
    "        p += i\n",
    "    p = p/len(results)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "322e328b-1224-4545-b16f-7ebac6baa626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faces': 1, 'pred': ['Female', 0.99969137]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_gender(imgs['test'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "aa133b69-6b02-4cd1-954f-73d8fc705b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faces': 1, 'pred': ['(20,29)', 0.98140407]}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_age(imgs['test'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "518d8b5e-ff1d-43a8-9a01-5f51c159ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:39<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for image in tqdm(imgs['test']):\n",
    "    user_id = int(image.split('/')[-1].split('.')[0])\n",
    "    predictions[user_id] = {'gender':predict_gender(image),\n",
    "                            'age':predict_age(image),\n",
    "                          'age_classes':predict_age_all_classes(image)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2f6fbfbb-3f59-4e6f-ab1e-0c6a1bd85173",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for u,d in predictions.items():\n",
    "    preds.append({'user_id':u,\n",
    "                  'pred_faces':d['gender']['faces'],\n",
    "                  'pred_gender_label':d['gender']['pred'][0],\n",
    "                  'pred_gender_prob':d['gender']['pred'][1],\n",
    "                  'pred_age_label':d['age']['pred'][0],\n",
    "                  'pred_age_prob':d['age']['pred'][1],\n",
    "                  'pred_age_0_19_prob':d['age_classes']['pred'][0],\n",
    "                  'pred_age_20_29_prob':d['age_classes']['pred'][1],\n",
    "                  'pred_age_30_39_prob':d['age_classes']['pred'][2],\n",
    "                  'pred_age_40_100_prob':d['age_classes']['pred'][3]\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "0d854919-8d18-4a76-b9f0-d7d68c6e1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to dataframe\n",
    "df_preds = pd.DataFrame.from_records(preds)\n",
    "df_preds['pred_is_male_label']=df_preds['pred_gender_label'].apply(lambda x: True if x=='Male' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7d6b3eb5-ed91-4ddf-8913-f81301e64ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9f77009e-3a4c-4d51-9932-3921a1e5196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_data = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/user_age_gender_location_test_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4cce18c2-5165-4580-8707-19b9b8f0b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_to_cat(age):\n",
    "    if age<=19:\n",
    "        return AGE_INTERVALS[0]\n",
    "    if age<=29:\n",
    "        return AGE_INTERVALS[1]\n",
    "    if age<=39:\n",
    "        return AGE_INTERVALS[2]\n",
    "    if age>=40:\n",
    "        return AGE_INTERVALS[3]\n",
    "\n",
    "test_data['age_cat'] = test_data['age'].apply(convert_age_to_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "71849c2d-96aa-449e-a524-836e2681bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(df_preds,on='user_id',how='inner',validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7d4c294f-c909-4a9d-aa35-05eea38ee7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval functions\n",
    "from sklearn.metrics import accuracy_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "82f2dc74-da95-43f1-8a70-229d89d7a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.7598214285714285\n",
      "F1: 0.8315591734502191\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.7957124842370744\n",
      "F1: 0.8457142857142858\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.8060109289617486\n",
      "F1: 0.8530020703933746\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gender\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['is_male'].astype(int)\n",
    "y_pred = test_data['pred_is_male_label'].astype(int)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'is_male'].astype(int)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_is_male_label'].astype(int)\n",
    "y_test_1 = test_data.loc[one_face,'is_male'].astype(int)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_is_male_label'].astype(int)\n",
    "print('Gender prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred)}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0)}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1)}\")\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a8503f8f-4f25-487a-97ff-9eeac1f8083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_cat(age_label):\n",
    "    return AGE_INTERVALS.index(age_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "69887605-95bc-411e-9651-e81d9d605a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.3678571428571429\n",
      "F1: 0.30282907571564344\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.26229508196721313\n",
      "F1: 0.2356312186942906\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.26366120218579236\n",
      "F1: 0.23839121406777658\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# age\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['age_cat'].apply(convert_age_cat)\n",
    "y_pred = test_data['pred_age_label'].apply(convert_age_cat)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "y_test_1 = test_data.loc[one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "print('Age prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1,average='macro')}\")\n",
    "print('-'*45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "mentalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
