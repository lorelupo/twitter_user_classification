{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79231f3e-809d-49d2-a7ee-47735096c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16f40cf3-4567-4e0a-92ce-341fe3e41791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model paths and labels\n",
    "model_dir = '/g100_scratch/userexternal/pbose000/mentalism/img_prediction/cv_models'\n",
    "GENDER_MODEL = os.path.join(model_dir, 'deploy_gender.prototxt')\n",
    "GENDER_PROTO = os.path.join(model_dir,'gender_net.caffemodel')\n",
    "AGE_MODEL = os.path.join(model_dir, 'deploy_age.prototxt')\n",
    "AGE_PROTO = os.path.join(model_dir,'age_net.caffemodel')\n",
    "FACE_PROTO = os.path.join(model_dir,'deploy.prototxt')\n",
    "FACE_MODEL =  os.path.join(model_dir,'res10_300x300_ssd_iter_140000_fp16.caffemodel')\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "GENDER_LIST = ['Male', 'Female']\n",
    "AGE_INTERVALS = ['(0, 19)', '(20,29)', '(30, 39)', '(40, 100)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa898ecb-11fb-4f6d-98dd-31296005be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define image paths and load all image paths\n",
    "img_dir = '/g100_work/IscrC_mental/data/user_classification/images/'\n",
    "imgs = {}\n",
    "imgs['train'] = glob.glob(os.path.join(img_dir,'train')+'/*')\n",
    "imgs['test'] = glob.glob(os.path.join(img_dir,'test')+'/*')\n",
    "imgs['de'] = glob.glob(os.path.join(img_dir,'de')+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d43381-5beb-4cb8-a04c-b2db42471040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load face Caffe model\n",
    "face_net = cv2.dnn.readNetFromCaffe(FACE_PROTO, FACE_MODEL)\n",
    "# Load gender prediction model\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_MODEL, GENDER_PROTO)\n",
    "age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ee58e7-f3b6-45d2-b5e0-34c34fa0b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize frame size\n",
    "frame_width = 1280\n",
    "frame_height = 720"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1c7914-1ca9-4aa0-8b2c-44234b7ffdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(frame, confidence_threshold=0.5):\n",
    "    # convert the frame into a blob to be ready for NN input\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), (104, 177.0, 123.0))\n",
    "    # set the image as input to the NN\n",
    "    face_net.setInput(blob)\n",
    "    # perform inference and get predictions\n",
    "    output = np.squeeze(face_net.forward())\n",
    "    # initialize the result list\n",
    "    faces = []\n",
    "    # Loop over the faces detected\n",
    "    for i in range(output.shape[0]):\n",
    "        confidence = output[i, 2]\n",
    "        if confidence > confidence_threshold:\n",
    "            box = output[i, 3:7] * \\\n",
    "                np.array([frame.shape[1], frame.shape[0],\n",
    "                         frame.shape[1], frame.shape[0]])\n",
    "            # convert to integers\n",
    "            start_x, start_y, end_x, end_y = box.astype(int)\n",
    "            # widen the box a little\n",
    "            start_x, start_y, end_x, end_y = start_x - \\\n",
    "                10, start_y - 10, end_x + 10, end_y + 10\n",
    "            start_x = 0 if start_x < 0 else start_x\n",
    "            start_y = 0 if start_y < 0 else start_y\n",
    "            end_x = 0 if end_x < 0 else end_x\n",
    "            end_y = 0 if end_y < 0 else end_y\n",
    "            # append to our list\n",
    "            faces.append((start_x, start_y, end_x, end_y))\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "391e2bfc-cd9f-473e-9600-5655ade301ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "    # resize the image\n",
    "    return cv2.resize(image, dim, interpolation = inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efdddcae-7447-4617-8cc5-ea804f88f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gender(input_path: str):\n",
    "    \"\"\"Predict the gender of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # resize the image, uncomment if you want to resize the image\n",
    "    # img = cv2.resize(img, (frame_width, frame_height))\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    # predict the faces\n",
    "    faces = get_faces(frame)\n",
    "    # Loop over the faces detected\n",
    "    # for idx, face in enumerate(faces):\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        # scale factor = After performing mean substraction we can optionally scale the image by some factor. (if 1 -> no scaling)\n",
    "        # size = The spatial size that the CNN expects. Options are = (224*224, 227*227 or 299*299)\n",
    "        # mean = mean substraction values to be substracted from every channel of the image.\n",
    "        # swapRB=OpenCV assumes images in BGR whereas the mean is supplied in RGB. To resolve this we set swapRB to True.\n",
    "        blob = cv2.dnn.blobFromImage(image=face_img, scalefactor=1.0, size=(\n",
    "            227, 227), mean=MODEL_MEAN_VALUES, swapRB=False, crop=False)\n",
    "        # Predict Gender\n",
    "        gender_net.setInput(blob)\n",
    "        gender_preds = gender_net.forward()\n",
    "        i = gender_preds[0].argmax()\n",
    "        gender = GENDER_LIST[i]\n",
    "        gender_confidence_score = gender_preds[0][i]\n",
    "        \n",
    "        # Label processed image\n",
    "        results.append([gender, gender_confidence_score])\n",
    "    \n",
    "    if len(results)==0:\n",
    "        results = ['Male',0.5]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_gender(results)\n",
    "    else:\n",
    "        results = results[0]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_gender(results):\n",
    "    p = 0\n",
    "    for i in results:\n",
    "        if i[0]=='Male':\n",
    "            p += i[1]\n",
    "        else:\n",
    "            p += 1 - i[1]\n",
    "    p = p/len(results)\n",
    "    if p>0.5:\n",
    "        return ['Male',p]\n",
    "    else:\n",
    "        return ['Female',1-p]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db34b71f-19c1-412d-883b-e60a2c375172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age(input_path: str):\n",
    "    \"\"\"Predict the age of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    faces = get_faces(frame)\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image=face_img, scalefactor=1.0, size=(227, 227), \n",
    "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "        )\n",
    "        # Predict Age\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_preds = convert_age_interval(age_preds[0])\n",
    "        #t = age_preds.argmax()\n",
    "        #age = AGE_INTERVALS[t]\n",
    "        #age_confidence_score = age_preds[t]\n",
    "        results.append(age_preds)\n",
    "    if len(results)==0:\n",
    "        results = [AGE_INTERVALS[3],0.25]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_age(results)\n",
    "    else:\n",
    "        t = results[0].argmax()\n",
    "        age = AGE_INTERVALS[t]\n",
    "        age_confidence_score = results[0][t]\n",
    "        results = [age,age_confidence_score]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_age(results):\n",
    "    p = np.zeros(len(results[0]))\n",
    "    for i in results:\n",
    "        p += i\n",
    "    p = p/len(results)\n",
    "    t = p.argmax()\n",
    "    age = AGE_INTERVALS[t]\n",
    "    age_confidence_score = p[t]\n",
    "    return [age,age_confidence_score]\n",
    "\n",
    "\n",
    "def convert_age_interval(age_preds):\n",
    "    ages=[age_preds[0]+age_preds[1]+age_preds[2]+age_preds[3],age_preds[4],age_preds[5],age_preds[6]+age_preds[7]]\n",
    "    return np.array(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263105df-c6e7-4060-97a5-ed122fe4c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age_all_classes(input_path: str):\n",
    "    \"\"\"Predict the age of the faces showing in the image\"\"\"\n",
    "    # Read Input Image\n",
    "    img = cv2.imread(input_path)\n",
    "    # Take a copy of the initial image and resize it\n",
    "    frame = img.copy()\n",
    "    if frame.shape[1] > frame_width:\n",
    "        frame = image_resize(frame, width=frame_width)\n",
    "    faces = get_faces(frame)\n",
    "    results = []\n",
    "    for i, (start_x, start_y, end_x, end_y) in enumerate(faces):\n",
    "        face_img = frame[start_y: end_y, start_x: end_x]\n",
    "        # image --> Input image to preprocess before passing it through our dnn for classification.\n",
    "        blob = cv2.dnn.blobFromImage(\n",
    "            image=face_img, scalefactor=1.0, size=(227, 227), \n",
    "            mean=MODEL_MEAN_VALUES, swapRB=False\n",
    "        )\n",
    "        # Predict Age\n",
    "        age_net.setInput(blob)\n",
    "        age_preds = age_net.forward()\n",
    "        age_preds = convert_age_interval(age_preds[0])\n",
    "        #t = age_preds.argmax()\n",
    "        #age = AGE_INTERVALS[t]\n",
    "        #age_confidence_score = age_preds[t]\n",
    "        results.append(age_preds)\n",
    "    if len(results)==0:\n",
    "        results = [0.25,0.25,0.25,0.25]\n",
    "    elif len(results)>1:\n",
    "        results = handle_multiple_results_age_classes(results)\n",
    "    else:\n",
    "        results = results[0]\n",
    "    return {'faces':len(faces),'pred':results}\n",
    "\n",
    "\n",
    "def handle_multiple_results_age_classes(results):\n",
    "    p = np.zeros(len(results[0]))\n",
    "    for i in results:\n",
    "        p += i\n",
    "    p = p/len(results)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "518d8b5e-ff1d-43a8-9a01-5f51c159ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1138/1138 [02:59<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for image in tqdm(imgs['test']):\n",
    "    user_id = int(image.split('/')[-1].split('.')[0])\n",
    "    predictions[user_id] = {'gender':predict_gender(image),\n",
    "                            'age':predict_age(image),\n",
    "                          'age_classes':predict_age_all_classes(image)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f6fbfbb-3f59-4e6f-ab1e-0c6a1bd85173",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for u,d in predictions.items():\n",
    "    preds.append({'user_id':u,\n",
    "                  'pred_faces':d['gender']['faces'],\n",
    "                  'pred_gender_label':d['gender']['pred'][0],\n",
    "                  'pred_gender_prob':d['gender']['pred'][1],\n",
    "                  'pred_age_label':d['age']['pred'][0],\n",
    "                  'pred_age_prob':d['age']['pred'][1],\n",
    "                  'pred_age_0_19_prob':d['age_classes']['pred'][0],\n",
    "                  'pred_age_20_29_prob':d['age_classes']['pred'][1],\n",
    "                  'pred_age_30_39_prob':d['age_classes']['pred'][2],\n",
    "                  'pred_age_40_100_prob':d['age_classes']['pred'][3]\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d854919-8d18-4a76-b9f0-d7d68c6e1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to dataframe\n",
    "df_preds = pd.DataFrame.from_records(preds)\n",
    "df_preds['pred_is_male_label']=df_preds['pred_gender_label'].apply(lambda x: True if x=='Male' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7d6b3eb5-ed91-4ddf-8913-f81301e64ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d031ad25-f5aa-46da-8f2d-bbdfd86f7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f77009e-3a4c-4d51-9932-3921a1e5196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_data = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/user_age_gender_location_test_set.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cce18c2-5165-4580-8707-19b9b8f0b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_to_cat(age):\n",
    "    if age<=19:\n",
    "        return AGE_INTERVALS[0]\n",
    "    if age<=29:\n",
    "        return AGE_INTERVALS[1]\n",
    "    if age<=39:\n",
    "        return AGE_INTERVALS[2]\n",
    "    if age>=40:\n",
    "        return AGE_INTERVALS[3]\n",
    "\n",
    "test_data['age_cat'] = test_data['age'].apply(convert_age_to_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71849c2d-96aa-449e-a524-836e2681bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(df_preds,on='user_id',how='inner',validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d4c294f-c909-4a9d-aa35-05eea38ee7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval functions\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82f2dc74-da95-43f1-8a70-229d89d7a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.7598214285714285\n",
      "F1: 0.7066038480003817\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.7957124842370744\n",
      "F1: 0.7717377398720682\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.8060109289617486\n",
      "F1: 0.7839307540721894\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gender\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['is_male'].astype(int)\n",
    "y_pred = test_data['pred_is_male_label'].astype(int)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'is_male'].astype(int)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_is_male_label'].astype(int)\n",
    "y_test_1 = test_data.loc[one_face,'is_male'].astype(int)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_is_male_label'].astype(int)\n",
    "print('Gender prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1,average='macro')}\")\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8503f8f-4f25-487a-97ff-9eeac1f8083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_cat(age_label):\n",
    "    return AGE_INTERVALS.index(age_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "69887605-95bc-411e-9651-e81d9d605a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.3517857142857143\n",
      "F1: 0.28103526583998184\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.23203026481715006\n",
      "F1: 0.20970163939312067\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.22950819672131148\n",
      "F1: 0.2087746534954376\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# age\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['age_cat'].apply(convert_age_cat)\n",
    "y_pred = test_data['pred_age_label'].apply(convert_age_cat)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "y_test_1 = test_data.loc[one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "print('Age prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1,average='macro')}\")\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee70cd2-c773-4864-b6a5-ee2edf0ca930",
   "metadata": {},
   "source": [
    "# train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32c8b380-fa49-47dc-b6a3-a05296fc928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15516/15516 [35:08<00:00,  7.36it/s] \n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for image in tqdm(imgs['train']):\n",
    "    user_id = int(image.split('/')[-1].split('.')[0])\n",
    "    predictions[user_id] = {'gender':predict_gender(image),\n",
    "                            'age':predict_age(image),\n",
    "                          'age_classes':predict_age_all_classes(image)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e714300-1661-4caa-b745-4fa46931bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for u,d in predictions.items():\n",
    "    preds.append({'user_id':u,\n",
    "                  'pred_faces':d['gender']['faces'],\n",
    "                  'pred_gender_label':d['gender']['pred'][0],\n",
    "                  'pred_gender_prob':d['gender']['pred'][1],\n",
    "                  'pred_age_label':d['age']['pred'][0],\n",
    "                  'pred_age_prob':d['age']['pred'][1],\n",
    "                  'pred_age_0_19_prob':d['age_classes']['pred'][0],\n",
    "                  'pred_age_20_29_prob':d['age_classes']['pred'][1],\n",
    "                  'pred_age_30_39_prob':d['age_classes']['pred'][2],\n",
    "                  'pred_age_40_100_prob':d['age_classes']['pred'][3]\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa6eede8-e2b3-49a1-827f-c3a9e009ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to dataframe\n",
    "df_preds = pd.DataFrame.from_records(preds)\n",
    "df_preds['pred_is_male_label']=df_preds['pred_gender_label'].apply(lambda x: True if x=='Male' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7043528-e522-4978-8d67-2d3f21ca450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744da1ae-f616-482d-83bf-fe968d6a18ea",
   "metadata": {},
   "source": [
    "# de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2116e6a-f49d-4ba5-87e5-5f0b9c55958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [01:12<00:00,  5.87it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "for image in tqdm(imgs['de']):\n",
    "    user_id = int(image.split('/')[-1].split('.')[0])\n",
    "    predictions[user_id] = {'gender':predict_gender(image),\n",
    "                            'age':predict_age(image),\n",
    "                          'age_classes':predict_age_all_classes(image)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0647f2b-e27e-45db-80bd-190e31775a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for u,d in predictions.items():\n",
    "    preds.append({'user_id':u,\n",
    "                  'pred_faces':d['gender']['faces'],\n",
    "                  'pred_gender_label':d['gender']['pred'][0],\n",
    "                  'pred_gender_prob':d['gender']['pred'][1],\n",
    "                  'pred_age_label':d['age']['pred'][0],\n",
    "                  'pred_age_prob':d['age']['pred'][1],\n",
    "                  'pred_age_0_19_prob':d['age_classes']['pred'][0],\n",
    "                  'pred_age_20_29_prob':d['age_classes']['pred'][1],\n",
    "                  'pred_age_30_39_prob':d['age_classes']['pred'][2],\n",
    "                  'pred_age_40_100_prob':d['age_classes']['pred'][3]\n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a71c9cb-5161-4e91-bd48-28d9062ec79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert predictions to dataframe\n",
    "df_preds = pd.DataFrame.from_records(preds)\n",
    "df_preds['pred_is_male_label']=df_preds['pred_gender_label'].apply(lambda x: True if x=='Male' else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f9745f-1b20-4043-b415-5684cb2ba882",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_pickle('/g100_work/IscrC_mental/data/user_classification/trained_models/cv_models_de.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db55e34-3f03-4e6d-8904-6171efc17982",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f082afd0-0b3e-470f-b934-381b895ad468",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "test_data = pd.read_pickle('/g100_work/IscrC_mental/data/user_classification/german_data/data_for_models_german_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f880f8e-6eef-4e79-9b25-0ea8a845bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_age_to_cat(age):\n",
    "    if age<=19:\n",
    "        return AGE_INTERVALS[0]\n",
    "    if age<=29:\n",
    "        return AGE_INTERVALS[1]\n",
    "    if age<=39:\n",
    "        return AGE_INTERVALS[2]\n",
    "    if age>=40:\n",
    "        return AGE_INTERVALS[3]\n",
    "\n",
    "test_data['age_cat'] = test_data['age'].apply(convert_age_to_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "325abbe3-bc70-4fd0-aa0b-c99e2d28387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.merge(df_preds,on='user_id',how='inner',validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "709ba874-c615-46a0-bc80-f90bf90b415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.7929411764705883\n",
      "F1: 0.6579351723128705\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.7942238267148014\n",
      "F1: 0.7088458205019454\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.8\n",
      "F1: 0.7149844000337295\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# gender\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['is_male'].astype(int)\n",
    "y_pred = test_data['pred_is_male_label'].astype(int)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'is_male'].astype(int)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_is_male_label'].astype(int)\n",
    "y_test_1 = test_data.loc[one_face,'is_male'].astype(int)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_is_male_label'].astype(int)\n",
    "print('Gender prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1,average='macro')}\")\n",
    "print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00c40e71-6a23-4554-991e-0cfd78813f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age prediction from images\n",
      "---------------------------------------------\n",
      "Sample: All\n",
      "Accuracy: 0.34823529411764703\n",
      "F1: 0.27895166016739537\n",
      "---------------------------------------------\n",
      "Sample: At least 1 face\n",
      "Accuracy: 0.30324909747292417\n",
      "F1: 0.2804223111343527\n",
      "---------------------------------------------\n",
      "Sample: Exactly 1 face\n",
      "Accuracy: 0.3076923076923077\n",
      "F1: 0.284134132078025\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# age\n",
    "at_least_one_face = test_data['pred_faces']>0\n",
    "one_face = test_data['pred_faces']==1\n",
    "y_test = test_data['age_cat'].apply(convert_age_cat)\n",
    "y_pred = test_data['pred_age_label'].apply(convert_age_cat)\n",
    "y_test_n0 = test_data.loc[at_least_one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_n0 = test_data.loc[at_least_one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "y_test_1 = test_data.loc[one_face,'age_cat'].apply(convert_age_cat)\n",
    "y_pred_1 = test_data.loc[one_face,'pred_age_label'].apply(convert_age_cat)\n",
    "print('Age prediction from images')\n",
    "print('-'*45)\n",
    "print('Sample: All')\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_pred)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_pred,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: At least 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_n0,y_pred_n0)}\")\n",
    "print(f\"F1: {f1_score(y_test_n0,y_pred_n0,average='macro')}\")\n",
    "print('-'*45)\n",
    "print('Sample: Exactly 1 face')\n",
    "print(f\"Accuracy: {accuracy_score(y_test_1,y_pred_1)}\")\n",
    "print(f\"F1: {f1_score(y_test_1,y_pred_1,average='macro')}\")\n",
    "print('-'*45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalenv",
   "language": "python",
   "name": "mentalenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
